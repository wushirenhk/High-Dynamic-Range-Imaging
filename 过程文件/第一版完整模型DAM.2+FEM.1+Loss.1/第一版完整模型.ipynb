{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c997b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DAM\n",
    "class DualAttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(DualAttentionModule, self).__init__()\n",
    "        # 输入图像的初始处理\n",
    "        self.initial_conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.initial_relu = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        # 像素注意力模块\n",
    "        self.pa_conv1 = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.pa_relu1 = nn.LeakyReLU(0.1)\n",
    "        self.pa_bn1 = nn.BatchNorm2d(in_channels // 8)\n",
    "        self.pa_conv2 = nn.Conv2d(in_channels // 8, 1, kernel_size=1)\n",
    "        self.pa_sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # 通道注意力模块\n",
    "        self.ca_gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.ca_conv1 = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.ca_relu1 = nn.LeakyReLU(0.1)\n",
    "        self.ca_conv2 = nn.Conv2d(in_channels // 8, in_channels, kernel_size=1)\n",
    "        self.ca_sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # 特征增强模块\n",
    "        self.fe_conv = nn.Conv2d(in_channels * 2, in_channels, kernel_size=3, padding=1)\n",
    "        self.fe_tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始处理\n",
    "        x2 = self.initial_conv(x)\n",
    "        x2 = self.initial_relu(x2)\n",
    "        \n",
    "        # 像素注意力\n",
    "        pa = self.pa_conv1(x2)\n",
    "        pa = self.pa_relu1(pa)\n",
    "        pa = self.pa_bn1(pa)\n",
    "        pa = self.pa_conv2(pa)\n",
    "        pa = self.pa_sigmoid(pa)\n",
    "        pa_out = x2 * pa\n",
    "        \n",
    "        # 通道注意力\n",
    "        ca = self.ca_gap(x2)\n",
    "        ca = self.ca_conv1(ca)\n",
    "        ca = self.ca_relu1(ca)\n",
    "        ca = self.ca_conv2(ca)\n",
    "        ca = self.ca_sigmoid(ca)\n",
    "        ca_out = x2 * ca\n",
    "        \n",
    "        # 拼接PA和CA的输出\n",
    "        concat = torch.cat([pa_out, ca_out], dim=1)\n",
    "        \n",
    "        # 最后两层\n",
    "        fe = self.fe_conv(concat)\n",
    "        fe = self.fe_tanh(fe)\n",
    "        \n",
    "        # 输出\n",
    "        out = fe + x + x + x2\n",
    "        \n",
    "        return out\n",
    "\n",
    "# FEM\n",
    "class FeatureEnhancementModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(FeatureEnhancementModule, self).__init__()\n",
    "\n",
    "        def conv_block(in_channels, out_channels, pool=True):\n",
    "            layers = [\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            ]\n",
    "            if pool:\n",
    "                layers.append(nn.MaxPool2d(2))\n",
    "            return nn.Sequential(*layers)\n",
    "        \n",
    "        def dilated_conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=2, dilation=2),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        self.fd_conv1 = conv_block(in_channels, in_channels, pool=True)\n",
    "        self.fd_conv2 = conv_block(in_channels, in_channels, pool=True)\n",
    "        self.fd_downsample1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, stride=2)\n",
    "        \n",
    "        self.fd_conv3 = conv_block(in_channels, in_channels, pool=True)\n",
    "        self.fd_conv4 = conv_block(in_channels, in_channels, pool=True)\n",
    "        self.fd_downsample2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, stride=2)\n",
    "        \n",
    "        self.fd_conv5 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.fd_relu5 = nn.LeakyReLU(0.1)\n",
    "        self.fd_bn5 = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "        self.fd_dilated_conv1 = dilated_conv_block(in_channels, in_channels)\n",
    "        self.fd_dilated_conv2 = dilated_conv_block(in_channels, in_channels)\n",
    "\n",
    "        self.fd_tanh = nn.Tanh()\n",
    "\n",
    "        self.fc_conv1 = conv_block(in_channels, in_channels, pool=True)\n",
    "        self.fc_conv2 = conv_block(in_channels, in_channels, pool=True)\n",
    "        self.fc_downsample1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, stride=2)\n",
    "        \n",
    "        self.fc_conv3 = conv_block(in_channels, in_channels, pool=True)\n",
    "        self.fc_conv4 = conv_block(in_channels, in_channels, pool=True)\n",
    "        self.fc_downsample2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, stride=2)\n",
    "        \n",
    "        self.fc_conv5 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.fc_relu5 = nn.LeakyReLU(0.1)\n",
    "        self.fc_bn5 = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "        self.fc_dilated_conv1 = dilated_conv_block(in_channels, in_channels)\n",
    "        self.fc_dilated_conv2 = dilated_conv_block(in_channels, in_channels)\n",
    "\n",
    "        self.fc_tanh = nn.Tanh()\n",
    "        self.fc_sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 细节补充分支（FD）\n",
    "        fd = self.fd_conv1(x)\n",
    "        fd = self.fd_conv2(fd)\n",
    "        fd = self.fd_downsample1(fd)\n",
    "        \n",
    "        fd = self.fd_conv3(fd)\n",
    "        fd = self.fd_conv4(fd)\n",
    "        fd = self.fd_downsample2(fd)\n",
    "        \n",
    "        fd = self.fd_conv5(fd)\n",
    "        fd = self.fd_relu5(fd)\n",
    "        fd = self.fd_bn5(fd)\n",
    "        \n",
    "        fd = self.fd_dilated_conv1(fd)\n",
    "        fd = self.fd_dilated_conv2(fd)\n",
    "        \n",
    "        fd = self.fd_tanh(fd)\n",
    "        fd_out = fd + x\n",
    "\n",
    "        # 颜色校正分支（FC）\n",
    "        fc = self.fc_conv1(x)\n",
    "        fc = self.fc_conv2(fc)\n",
    "        fc = self.fc_downsample1(fc)\n",
    "        \n",
    "        fc = self.fc_conv3(fc)\n",
    "        fc = self.fc_conv4(fc)\n",
    "        fc = self.fc_downsample2(fc)\n",
    "        \n",
    "        fc = self.fc_conv5(fc)\n",
    "        fc = self.fc_relu5(fc)\n",
    "        fc = self.fc_bn5(fc)\n",
    "        \n",
    "        fc = self.fc_dilated_conv1(fc)\n",
    "        fc = self.fc_dilated_conv2(fc)\n",
    "        \n",
    "        fc = self.fc_tanh(fc)\n",
    "        fc = self.fc_sigmoid(fc)\n",
    "        fc_out = fc / x\n",
    "\n",
    "        # 最终融合\n",
    "        out = fd_out + fc_out\n",
    "        return out\n",
    "\n",
    "# 定义 HDRNet 模型\n",
    "class HDRNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(HDRNet, self).__init__()\n",
    "        self.dam = DualAttentionModule(in_channels)\n",
    "        self.fem = FeatureEnhancementModule(in_channels)\n",
    "        self.final_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # 欠曝光（记作1）\n",
    "        x1_dam = self.dam(x1)\n",
    "        # 过曝光（记作2）\n",
    "        x2_dam = self.dam(x2)\n",
    "\n",
    "        # 初步融合\n",
    "        x3 = x1 * x1_dam\n",
    "        x4 = x2 * x2_dam\n",
    "        x_fusion = x3 + x4\n",
    "\n",
    "        # 特征增强模块\n",
    "        x_enhanced = self.fem(x_fusion)\n",
    "\n",
    "        # 最终卷积\n",
    "        out = self.final_conv(x_enhanced)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# 定义损失函数\n",
    "class HDRLoss(nn.Module):\n",
    "    def __init__(self, vgg_model):\n",
    "        super(HDRLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.vgg = vgg_model\n",
    "\n",
    "    def forward(self, Ihdr, Iref, Iu, Io):\n",
    "        mse_loss = self.mse_loss(Ihdr, Iref)\n",
    "        Ihdr_vgg = self.vgg(Ihdr)\n",
    "        Iref_vgg = self.vgg(Iref)\n",
    "        perceptual_loss = F.mse_loss(Ihdr_vgg, Iref_vgg)\n",
    "\n",
    "        mef_ssim_loss = 1 - calculate_mef_ssim(Ihdr, Iref)\n",
    "        adversarial_loss = calculate_adversarial_loss(Ihdr, Iref)\n",
    "        global_local_contrast_loss = calculate_global_local_contrast_loss(Ihdr, Iref, Iu, Io)\n",
    "\n",
    "        total_loss = mse_loss + 0.1 * mef_ssim_loss + 0.1 * adversarial_loss + 0.1 * perceptual_loss + 0.1 * global_local_contrast_loss\n",
    "        return total_loss\n",
    "\n",
    "def calculate_mef_ssim(Ihdr, Iref):\n",
    "    return 0.9  # 示例返回值\n",
    "\n",
    "def calculate_adversarial_loss(Ihdr, Iref):\n",
    "    return 0.1  # 示例返回值\n",
    "\n",
    "def calculate_global_local_contrast_loss(Ihdr, Iref, Iu, Io):\n",
    "    return 0.05  # 示例返回值\n",
    "\n",
    "def load_image(image_path, transform):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "def train_model(model, loss_fn, optimizer, dataloader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in dataloader:\n",
    "            input_image1, input_image2, ref_image = batch\n",
    "            output_image = model(input_image1, input_image2)\n",
    "            loss = loss_fn(output_image, ref_image, input_image1, input_image2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# 加载预训练的VGG-16模型\n",
    "vgg_model = vgg16(pretrained=True).features[:16].eval()\n",
    "for param in vgg_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = HDRNet(in_channels=3, out_channels=3)\n",
    "loss_fn = HDRLoss(vgg_model=vgg_model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "image_path1 = 'path_to_underexposed_image.jpg'\n",
    "image_path2 = 'path_to_overexposed_image.jpg'\n",
    "ref_image_path = 'path_to_reference_image.jpg'\n",
    "\n",
    "input_image1 = load_image(image_path1, transform)\n",
    "input_image2 = load_image(image_path2, transform)\n",
    "ref_image = load_image(ref_image_path, transform)\n",
    "\n",
    "dataloader = [(input_image1, input_image2, ref_image)]\n",
    "\n",
    "train_model(model, loss_fn, optimizer, dataloader, num_epochs=200)\n",
    "\n",
    "torch.save(model.state_dict(), 'hdrnet_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
