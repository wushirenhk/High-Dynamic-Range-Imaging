{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33c997b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n",
      "Epoch [1/500], Loss: 5.588217258453369, PSNR: -1.2158, SSIM: 0.0721, LPIPS: 0.7497\n",
      "Epoch [2/500], Loss: 5.461966514587402, PSNR: -1.1254, SSIM: 0.0717, LPIPS: 0.7500\n",
      "Epoch [3/500], Loss: 5.345733642578125, PSNR: -1.0304, SSIM: 0.0721, LPIPS: 0.7497\n",
      "Epoch [4/500], Loss: 5.240632057189941, PSNR: -0.9314, SSIM: 0.0728, LPIPS: 0.7484\n",
      "Epoch [5/500], Loss: 5.1426825523376465, PSNR: -0.8326, SSIM: 0.0735, LPIPS: 0.7478\n",
      "Epoch [6/500], Loss: 5.048066139221191, PSNR: -0.7313, SSIM: 0.0743, LPIPS: 0.7467\n",
      "Epoch [7/500], Loss: 4.961204528808594, PSNR: -0.6378, SSIM: 0.0757, LPIPS: 0.7456\n",
      "Epoch [8/500], Loss: 4.881417751312256, PSNR: -0.5469, SSIM: 0.0771, LPIPS: 0.7443\n",
      "Epoch [9/500], Loss: 4.804139137268066, PSNR: -0.4586, SSIM: 0.0785, LPIPS: 0.7428\n",
      "Epoch [10/500], Loss: 4.7306718826293945, PSNR: -0.3726, SSIM: 0.0795, LPIPS: 0.7415\n",
      "Epoch [11/500], Loss: 4.663095474243164, PSNR: -0.2884, SSIM: 0.0808, LPIPS: 0.7402\n",
      "Epoch [12/500], Loss: 4.598258018493652, PSNR: -0.2063, SSIM: 0.0822, LPIPS: 0.7387\n",
      "Epoch [13/500], Loss: 4.536892890930176, PSNR: -0.1260, SSIM: 0.0838, LPIPS: 0.7373\n",
      "Epoch [14/500], Loss: 4.4776105880737305, PSNR: -0.0479, SSIM: 0.0849, LPIPS: 0.7360\n",
      "Epoch [15/500], Loss: 4.421463966369629, PSNR: 0.0285, SSIM: 0.0862, LPIPS: 0.7347\n",
      "Epoch [16/500], Loss: 4.367514610290527, PSNR: 0.1033, SSIM: 0.0874, LPIPS: 0.7335\n",
      "Epoch [17/500], Loss: 4.315352916717529, PSNR: 0.1765, SSIM: 0.0887, LPIPS: 0.7324\n",
      "Epoch [18/500], Loss: 4.266237258911133, PSNR: 0.2481, SSIM: 0.0906, LPIPS: 0.7314\n",
      "Epoch [19/500], Loss: 4.218475341796875, PSNR: 0.3179, SSIM: 0.0915, LPIPS: 0.7304\n",
      "Epoch [20/500], Loss: 4.173676013946533, PSNR: 0.3862, SSIM: 0.0922, LPIPS: 0.7291\n",
      "Epoch [21/500], Loss: 4.1299896240234375, PSNR: 0.4531, SSIM: 0.0933, LPIPS: 0.7280\n",
      "Epoch [22/500], Loss: 4.0881829261779785, PSNR: 0.5185, SSIM: 0.0950, LPIPS: 0.7272\n",
      "Epoch [23/500], Loss: 4.047916889190674, PSNR: 0.5826, SSIM: 0.0958, LPIPS: 0.7262\n",
      "Epoch [24/500], Loss: 4.009646892547607, PSNR: 0.6454, SSIM: 0.0965, LPIPS: 0.7252\n",
      "Epoch [25/500], Loss: 3.972639799118042, PSNR: 0.7069, SSIM: 0.0976, LPIPS: 0.7243\n",
      "Epoch [26/500], Loss: 3.9375381469726562, PSNR: 0.7672, SSIM: 0.0991, LPIPS: 0.7235\n",
      "Epoch [27/500], Loss: 3.9027111530303955, PSNR: 0.8264, SSIM: 0.0994, LPIPS: 0.7227\n",
      "Epoch [28/500], Loss: 3.8695147037506104, PSNR: 0.8844, SSIM: 0.1006, LPIPS: 0.7220\n",
      "Epoch [29/500], Loss: 3.838285446166992, PSNR: 0.9413, SSIM: 0.1007, LPIPS: 0.7212\n",
      "Epoch [30/500], Loss: 3.8065412044525146, PSNR: 0.9971, SSIM: 0.1017, LPIPS: 0.7203\n",
      "Epoch [31/500], Loss: 3.7787845134735107, PSNR: 1.0519, SSIM: 0.1032, LPIPS: 0.7192\n",
      "Epoch [32/500], Loss: 3.747495651245117, PSNR: 1.1056, SSIM: 0.1040, LPIPS: 0.7187\n",
      "Epoch [33/500], Loss: 3.7214584350585938, PSNR: 1.1585, SSIM: 0.1034, LPIPS: 0.7178\n",
      "Epoch [34/500], Loss: 3.692293882369995, PSNR: 1.2106, SSIM: 0.1041, LPIPS: 0.7168\n",
      "Epoch [35/500], Loss: 3.664588689804077, PSNR: 1.2617, SSIM: 0.1062, LPIPS: 0.7155\n",
      "Epoch [36/500], Loss: 3.6390132904052734, PSNR: 1.3122, SSIM: 0.1067, LPIPS: 0.7144\n",
      "Epoch [37/500], Loss: 3.6108219623565674, PSNR: 1.3619, SSIM: 0.1073, LPIPS: 0.7137\n",
      "Epoch [38/500], Loss: 3.587122917175293, PSNR: 1.4112, SSIM: 0.1065, LPIPS: 0.7129\n",
      "Epoch [39/500], Loss: 3.56223726272583, PSNR: 1.4597, SSIM: 0.1070, LPIPS: 0.7119\n",
      "Epoch [40/500], Loss: 3.5358381271362305, PSNR: 1.5077, SSIM: 0.1085, LPIPS: 0.7107\n",
      "Epoch [41/500], Loss: 3.51450514793396, PSNR: 1.5552, SSIM: 0.1089, LPIPS: 0.7098\n",
      "Epoch [42/500], Loss: 3.4906136989593506, PSNR: 1.6031, SSIM: 0.1092, LPIPS: 0.7087\n",
      "Epoch [43/500], Loss: 3.466644525527954, PSNR: 1.6513, SSIM: 0.1098, LPIPS: 0.7073\n",
      "Epoch [44/500], Loss: 3.4431872367858887, PSNR: 1.6997, SSIM: 0.1102, LPIPS: 0.7060\n",
      "Epoch [45/500], Loss: 3.4201154708862305, PSNR: 1.7489, SSIM: 0.1105, LPIPS: 0.7049\n",
      "Epoch [46/500], Loss: 3.3962819576263428, PSNR: 1.7999, SSIM: 0.1111, LPIPS: 0.7040\n",
      "Epoch [47/500], Loss: 3.3743200302124023, PSNR: 1.8512, SSIM: 0.1105, LPIPS: 0.7034\n",
      "Epoch [48/500], Loss: 3.3524680137634277, PSNR: 1.9026, SSIM: 0.1109, LPIPS: 0.7025\n",
      "Epoch [49/500], Loss: 3.328723430633545, PSNR: 1.9541, SSIM: 0.1122, LPIPS: 0.7011\n",
      "Epoch [50/500], Loss: 3.3079771995544434, PSNR: 2.0058, SSIM: 0.1131, LPIPS: 0.6997\n",
      "Epoch [51/500], Loss: 3.2873902320861816, PSNR: 2.0578, SSIM: 0.1133, LPIPS: 0.6985\n",
      "Epoch [52/500], Loss: 3.267153263092041, PSNR: 2.1100, SSIM: 0.1135, LPIPS: 0.6974\n",
      "Epoch [53/500], Loss: 3.246774196624756, PSNR: 2.1631, SSIM: 0.1135, LPIPS: 0.6962\n",
      "Epoch [54/500], Loss: 3.2262344360351562, PSNR: 2.2165, SSIM: 0.1136, LPIPS: 0.6951\n",
      "Epoch [55/500], Loss: 3.2056732177734375, PSNR: 2.2697, SSIM: 0.1134, LPIPS: 0.6942\n",
      "Epoch [56/500], Loss: 3.1855266094207764, PSNR: 2.3227, SSIM: 0.1127, LPIPS: 0.6935\n",
      "Epoch [57/500], Loss: 3.166929244995117, PSNR: 2.3757, SSIM: 0.1116, LPIPS: 0.6923\n",
      "Epoch [58/500], Loss: 3.1467819213867188, PSNR: 2.4284, SSIM: 0.1114, LPIPS: 0.6913\n",
      "Epoch [59/500], Loss: 3.12748646736145, PSNR: 2.4812, SSIM: 0.1114, LPIPS: 0.6899\n",
      "Epoch [60/500], Loss: 3.10876727104187, PSNR: 2.5332, SSIM: 0.1106, LPIPS: 0.6887\n",
      "Epoch [61/500], Loss: 3.090144634246826, PSNR: 2.5846, SSIM: 0.1097, LPIPS: 0.6875\n",
      "Epoch [62/500], Loss: 3.071604013442993, PSNR: 2.6351, SSIM: 0.1089, LPIPS: 0.6865\n",
      "Epoch [63/500], Loss: 3.053220272064209, PSNR: 2.6848, SSIM: 0.1082, LPIPS: 0.6855\n",
      "Epoch [64/500], Loss: 3.035097599029541, PSNR: 2.7341, SSIM: 0.1075, LPIPS: 0.6846\n",
      "Epoch [65/500], Loss: 3.0173702239990234, PSNR: 2.7832, SSIM: 0.1067, LPIPS: 0.6838\n",
      "Epoch [66/500], Loss: 3.0000338554382324, PSNR: 2.8327, SSIM: 0.1057, LPIPS: 0.6828\n",
      "Epoch [67/500], Loss: 2.982783317565918, PSNR: 2.8821, SSIM: 0.1045, LPIPS: 0.6817\n",
      "Epoch [68/500], Loss: 2.966362476348877, PSNR: 2.9318, SSIM: 0.1034, LPIPS: 0.6805\n",
      "Epoch [69/500], Loss: 2.950235366821289, PSNR: 2.9813, SSIM: 0.1028, LPIPS: 0.6792\n",
      "Epoch [70/500], Loss: 2.934086322784424, PSNR: 3.0296, SSIM: 0.1018, LPIPS: 0.6781\n",
      "Epoch [71/500], Loss: 2.918463945388794, PSNR: 3.0775, SSIM: 0.1007, LPIPS: 0.6771\n",
      "Epoch [72/500], Loss: 2.9028220176696777, PSNR: 3.1255, SSIM: 0.1002, LPIPS: 0.6758\n",
      "Epoch [73/500], Loss: 2.8873298168182373, PSNR: 3.1731, SSIM: 0.0992, LPIPS: 0.6747\n",
      "Epoch [74/500], Loss: 2.872375011444092, PSNR: 3.2203, SSIM: 0.0976, LPIPS: 0.6738\n",
      "Epoch [75/500], Loss: 2.8570950031280518, PSNR: 3.2675, SSIM: 0.0969, LPIPS: 0.6725\n",
      "Epoch [76/500], Loss: 2.8425660133361816, PSNR: 3.3147, SSIM: 0.0962, LPIPS: 0.6709\n",
      "Epoch [77/500], Loss: 2.8277225494384766, PSNR: 3.3602, SSIM: 0.0949, LPIPS: 0.6698\n",
      "Epoch [78/500], Loss: 2.8133950233459473, PSNR: 3.4059, SSIM: 0.0940, LPIPS: 0.6685\n",
      "Epoch [79/500], Loss: 2.799680709838867, PSNR: 3.4516, SSIM: 0.0934, LPIPS: 0.6671\n",
      "Epoch [80/500], Loss: 2.7852630615234375, PSNR: 3.4957, SSIM: 0.0924, LPIPS: 0.6661\n",
      "Epoch [81/500], Loss: 2.7718231678009033, PSNR: 3.5400, SSIM: 0.0914, LPIPS: 0.6651\n",
      "Epoch [82/500], Loss: 2.7581253051757812, PSNR: 3.5851, SSIM: 0.0908, LPIPS: 0.6638\n",
      "Epoch [83/500], Loss: 2.7448716163635254, PSNR: 3.6301, SSIM: 0.0901, LPIPS: 0.6625\n",
      "Epoch [84/500], Loss: 2.7318718433380127, PSNR: 3.6741, SSIM: 0.0888, LPIPS: 0.6617\n",
      "Epoch [85/500], Loss: 2.7183001041412354, PSNR: 3.7191, SSIM: 0.0879, LPIPS: 0.6605\n",
      "Epoch [86/500], Loss: 2.705336093902588, PSNR: 3.7645, SSIM: 0.0873, LPIPS: 0.6590\n",
      "Epoch [87/500], Loss: 2.6921024322509766, PSNR: 3.8077, SSIM: 0.0865, LPIPS: 0.6582\n",
      "Epoch [88/500], Loss: 2.6798558235168457, PSNR: 3.8506, SSIM: 0.0857, LPIPS: 0.6573\n",
      "Epoch [89/500], Loss: 2.6675047874450684, PSNR: 3.8936, SSIM: 0.0849, LPIPS: 0.6560\n",
      "Epoch [90/500], Loss: 2.655083656311035, PSNR: 3.9358, SSIM: 0.0840, LPIPS: 0.6549\n",
      "Epoch [91/500], Loss: 2.6430282592773438, PSNR: 3.9772, SSIM: 0.0830, LPIPS: 0.6537\n",
      "Epoch [92/500], Loss: 2.630969524383545, PSNR: 4.0174, SSIM: 0.0822, LPIPS: 0.6528\n",
      "Epoch [93/500], Loss: 2.6190664768218994, PSNR: 4.0567, SSIM: 0.0817, LPIPS: 0.6519\n",
      "Epoch [94/500], Loss: 2.6076717376708984, PSNR: 4.0961, SSIM: 0.0811, LPIPS: 0.6509\n",
      "Epoch [95/500], Loss: 2.596344232559204, PSNR: 4.1357, SSIM: 0.0803, LPIPS: 0.6500\n",
      "Epoch [96/500], Loss: 2.5849251747131348, PSNR: 4.1756, SSIM: 0.0797, LPIPS: 0.6488\n",
      "Epoch [97/500], Loss: 2.57426118850708, PSNR: 4.2154, SSIM: 0.0791, LPIPS: 0.6476\n",
      "Epoch [98/500], Loss: 2.5628273487091064, PSNR: 4.2532, SSIM: 0.0784, LPIPS: 0.6468\n",
      "Epoch [99/500], Loss: 2.552199363708496, PSNR: 4.2914, SSIM: 0.0778, LPIPS: 0.6458\n",
      "Epoch [100/500], Loss: 2.5425782203674316, PSNR: 4.3303, SSIM: 0.0774, LPIPS: 0.6446\n",
      "Epoch [101/500], Loss: 2.5320420265197754, PSNR: 4.3685, SSIM: 0.0770, LPIPS: 0.6429\n",
      "Epoch [102/500], Loss: 2.521543264389038, PSNR: 4.4054, SSIM: 0.0768, LPIPS: 0.6416\n",
      "Epoch [103/500], Loss: 2.511314868927002, PSNR: 4.4409, SSIM: 0.0765, LPIPS: 0.6408\n",
      "Epoch [104/500], Loss: 2.501173496246338, PSNR: 4.4764, SSIM: 0.0760, LPIPS: 0.6400\n",
      "Epoch [105/500], Loss: 2.490905284881592, PSNR: 4.5128, SSIM: 0.0754, LPIPS: 0.6389\n",
      "Epoch [106/500], Loss: 2.4815378189086914, PSNR: 4.5491, SSIM: 0.0748, LPIPS: 0.6379\n",
      "Epoch [107/500], Loss: 2.4721999168395996, PSNR: 4.5848, SSIM: 0.0744, LPIPS: 0.6370\n",
      "Epoch [108/500], Loss: 2.462771415710449, PSNR: 4.6199, SSIM: 0.0743, LPIPS: 0.6359\n",
      "Epoch [109/500], Loss: 2.454127550125122, PSNR: 4.6551, SSIM: 0.0741, LPIPS: 0.6349\n",
      "Epoch [110/500], Loss: 2.4451727867126465, PSNR: 4.6911, SSIM: 0.0739, LPIPS: 0.6339\n",
      "Epoch [111/500], Loss: 2.4364874362945557, PSNR: 4.7280, SSIM: 0.0736, LPIPS: 0.6321\n",
      "Epoch [112/500], Loss: 2.428345203399658, PSNR: 4.7642, SSIM: 0.0734, LPIPS: 0.6309\n",
      "Epoch [113/500], Loss: 2.4196481704711914, PSNR: 4.7989, SSIM: 0.0733, LPIPS: 0.6302\n",
      "Epoch [114/500], Loss: 2.4119486808776855, PSNR: 4.8333, SSIM: 0.0732, LPIPS: 0.6297\n",
      "Epoch [115/500], Loss: 2.4035768508911133, PSNR: 4.8702, SSIM: 0.0730, LPIPS: 0.6283\n",
      "Epoch [116/500], Loss: 2.3963818550109863, PSNR: 4.9067, SSIM: 0.0728, LPIPS: 0.6271\n",
      "Epoch [117/500], Loss: 2.388472318649292, PSNR: 4.9414, SSIM: 0.0729, LPIPS: 0.6264\n",
      "Epoch [118/500], Loss: 2.3813939094543457, PSNR: 4.9763, SSIM: 0.0730, LPIPS: 0.6257\n",
      "Epoch [119/500], Loss: 2.3739118576049805, PSNR: 5.0122, SSIM: 0.0730, LPIPS: 0.6245\n",
      "Epoch [120/500], Loss: 2.3672564029693604, PSNR: 5.0485, SSIM: 0.0729, LPIPS: 0.6233\n",
      "Epoch [121/500], Loss: 2.3599538803100586, PSNR: 5.0824, SSIM: 0.0731, LPIPS: 0.6228\n",
      "Epoch [122/500], Loss: 2.3533616065979004, PSNR: 5.1168, SSIM: 0.0732, LPIPS: 0.6222\n",
      "Epoch [123/500], Loss: 2.3467025756835938, PSNR: 5.1527, SSIM: 0.0732, LPIPS: 0.6210\n",
      "Epoch [124/500], Loss: 2.3400821685791016, PSNR: 5.1864, SSIM: 0.0733, LPIPS: 0.6206\n",
      "Epoch [125/500], Loss: 2.3339059352874756, PSNR: 5.2192, SSIM: 0.0735, LPIPS: 0.6201\n",
      "Epoch [126/500], Loss: 2.3275575637817383, PSNR: 5.2528, SSIM: 0.0735, LPIPS: 0.6191\n",
      "Epoch [127/500], Loss: 2.321603775024414, PSNR: 5.2860, SSIM: 0.0736, LPIPS: 0.6182\n",
      "Epoch [128/500], Loss: 2.3155007362365723, PSNR: 5.3173, SSIM: 0.0738, LPIPS: 0.6174\n",
      "Epoch [129/500], Loss: 2.309708833694458, PSNR: 5.3487, SSIM: 0.0740, LPIPS: 0.6166\n",
      "Epoch [130/500], Loss: 2.3040964603424072, PSNR: 5.3808, SSIM: 0.0739, LPIPS: 0.6158\n",
      "Epoch [131/500], Loss: 2.298222064971924, PSNR: 5.4108, SSIM: 0.0742, LPIPS: 0.6151\n",
      "Epoch [132/500], Loss: 2.29280948638916, PSNR: 5.4407, SSIM: 0.0744, LPIPS: 0.6143\n",
      "Epoch [133/500], Loss: 2.2872796058654785, PSNR: 5.4717, SSIM: 0.0744, LPIPS: 0.6133\n",
      "Epoch [134/500], Loss: 2.2817487716674805, PSNR: 5.5011, SSIM: 0.0746, LPIPS: 0.6127\n",
      "Epoch [135/500], Loss: 2.2766177654266357, PSNR: 5.5298, SSIM: 0.0748, LPIPS: 0.6122\n",
      "Epoch [136/500], Loss: 2.271475315093994, PSNR: 5.5598, SSIM: 0.0747, LPIPS: 0.6114\n",
      "Epoch [137/500], Loss: 2.2663722038269043, PSNR: 5.5882, SSIM: 0.0748, LPIPS: 0.6106\n",
      "Epoch [138/500], Loss: 2.2613935470581055, PSNR: 5.6152, SSIM: 0.0752, LPIPS: 0.6098\n",
      "Epoch [139/500], Loss: 2.256568670272827, PSNR: 5.6426, SSIM: 0.0752, LPIPS: 0.6090\n",
      "Epoch [140/500], Loss: 2.2516863346099854, PSNR: 5.6700, SSIM: 0.0752, LPIPS: 0.6084\n",
      "Epoch [141/500], Loss: 2.2469143867492676, PSNR: 5.6968, SSIM: 0.0752, LPIPS: 0.6080\n",
      "Epoch [142/500], Loss: 2.242173194885254, PSNR: 5.7229, SSIM: 0.0753, LPIPS: 0.6076\n",
      "Epoch [143/500], Loss: 2.2374634742736816, PSNR: 5.7490, SSIM: 0.0753, LPIPS: 0.6066\n",
      "Epoch [144/500], Loss: 2.2328481674194336, PSNR: 5.7742, SSIM: 0.0754, LPIPS: 0.6057\n",
      "Epoch [145/500], Loss: 2.228290319442749, PSNR: 5.7988, SSIM: 0.0755, LPIPS: 0.6049\n",
      "Epoch [146/500], Loss: 2.223796844482422, PSNR: 5.8237, SSIM: 0.0755, LPIPS: 0.6039\n",
      "Epoch [147/500], Loss: 2.2192509174346924, PSNR: 5.8478, SSIM: 0.0756, LPIPS: 0.6030\n",
      "Epoch [148/500], Loss: 2.214797258377075, PSNR: 5.8708, SSIM: 0.0759, LPIPS: 0.6023\n",
      "Epoch [149/500], Loss: 2.2102959156036377, PSNR: 5.8942, SSIM: 0.0759, LPIPS: 0.6012\n",
      "Epoch [150/500], Loss: 2.2061080932617188, PSNR: 5.9173, SSIM: 0.0759, LPIPS: 0.6001\n",
      "Epoch [151/500], Loss: 2.2021663188934326, PSNR: 5.9380, SSIM: 0.0762, LPIPS: 0.5993\n",
      "Epoch [152/500], Loss: 2.1975128650665283, PSNR: 5.9613, SSIM: 0.0760, LPIPS: 0.5981\n",
      "Epoch [153/500], Loss: 2.1935391426086426, PSNR: 5.9838, SSIM: 0.0759, LPIPS: 0.5972\n",
      "Epoch [154/500], Loss: 2.1896257400512695, PSNR: 6.0036, SSIM: 0.0762, LPIPS: 0.5966\n",
      "Epoch [155/500], Loss: 2.1850221157073975, PSNR: 6.0261, SSIM: 0.0761, LPIPS: 0.5958\n",
      "Epoch [156/500], Loss: 2.1814332008361816, PSNR: 6.0491, SSIM: 0.0757, LPIPS: 0.5948\n",
      "Epoch [157/500], Loss: 2.1768364906311035, PSNR: 6.0687, SSIM: 0.0760, LPIPS: 0.5942\n",
      "Epoch [158/500], Loss: 2.1732382774353027, PSNR: 6.0886, SSIM: 0.0763, LPIPS: 0.5936\n",
      "Epoch [159/500], Loss: 2.1687328815460205, PSNR: 6.1111, SSIM: 0.0760, LPIPS: 0.5922\n",
      "Epoch [160/500], Loss: 2.1652159690856934, PSNR: 6.1327, SSIM: 0.0759, LPIPS: 0.5911\n",
      "Epoch [161/500], Loss: 2.1609950065612793, PSNR: 6.1515, SSIM: 0.0764, LPIPS: 0.5908\n",
      "Epoch [162/500], Loss: 2.157341480255127, PSNR: 6.1718, SSIM: 0.0765, LPIPS: 0.5902\n",
      "Epoch [163/500], Loss: 2.153106212615967, PSNR: 6.1943, SSIM: 0.0762, LPIPS: 0.5888\n",
      "Epoch [164/500], Loss: 2.149280309677124, PSNR: 6.2149, SSIM: 0.0763, LPIPS: 0.5882\n",
      "Epoch [165/500], Loss: 2.145537853240967, PSNR: 6.2337, SSIM: 0.0767, LPIPS: 0.5880\n",
      "Epoch [166/500], Loss: 2.1413733959198, PSNR: 6.2547, SSIM: 0.0766, LPIPS: 0.5872\n",
      "Epoch [167/500], Loss: 2.1379027366638184, PSNR: 6.2764, SSIM: 0.0763, LPIPS: 0.5862\n",
      "Epoch [168/500], Loss: 2.133852958679199, PSNR: 6.2964, SSIM: 0.0764, LPIPS: 0.5857\n",
      "Epoch [169/500], Loss: 2.1305036544799805, PSNR: 6.3158, SSIM: 0.0767, LPIPS: 0.5853\n",
      "Epoch [170/500], Loss: 2.1266520023345947, PSNR: 6.3377, SSIM: 0.0764, LPIPS: 0.5842\n",
      "Epoch [171/500], Loss: 2.123262882232666, PSNR: 6.3584, SSIM: 0.0764, LPIPS: 0.5835\n",
      "Epoch [172/500], Loss: 2.119495391845703, PSNR: 6.3777, SSIM: 0.0767, LPIPS: 0.5830\n",
      "Epoch [173/500], Loss: 2.11598539352417, PSNR: 6.3979, SSIM: 0.0768, LPIPS: 0.5822\n",
      "Epoch [174/500], Loss: 2.112766742706299, PSNR: 6.4195, SSIM: 0.0766, LPIPS: 0.5815\n",
      "Epoch [175/500], Loss: 2.10915470123291, PSNR: 6.4391, SSIM: 0.0769, LPIPS: 0.5806\n",
      "Epoch [176/500], Loss: 2.1059160232543945, PSNR: 6.4573, SSIM: 0.0772, LPIPS: 0.5800\n",
      "Epoch [177/500], Loss: 2.1020169258117676, PSNR: 6.4783, SSIM: 0.0772, LPIPS: 0.5791\n",
      "Epoch [178/500], Loss: 2.099350929260254, PSNR: 6.4987, SSIM: 0.0772, LPIPS: 0.5781\n",
      "Epoch [179/500], Loss: 2.0961239337921143, PSNR: 6.5155, SSIM: 0.0778, LPIPS: 0.5777\n",
      "Epoch [180/500], Loss: 2.092080593109131, PSNR: 6.5355, SSIM: 0.0778, LPIPS: 0.5766\n",
      "Epoch [181/500], Loss: 2.089503765106201, PSNR: 6.5571, SSIM: 0.0777, LPIPS: 0.5756\n",
      "Epoch [182/500], Loss: 2.0855658054351807, PSNR: 6.5755, SSIM: 0.0780, LPIPS: 0.5749\n",
      "Epoch [183/500], Loss: 2.082559585571289, PSNR: 6.5938, SSIM: 0.0784, LPIPS: 0.5741\n",
      "Epoch [184/500], Loss: 2.0794501304626465, PSNR: 6.6140, SSIM: 0.0784, LPIPS: 0.5731\n",
      "Epoch [185/500], Loss: 2.07616925239563, PSNR: 6.6329, SSIM: 0.0787, LPIPS: 0.5725\n",
      "Epoch [186/500], Loss: 2.073185443878174, PSNR: 6.6519, SSIM: 0.0791, LPIPS: 0.5719\n",
      "Epoch [187/500], Loss: 2.0700228214263916, PSNR: 6.6715, SSIM: 0.0791, LPIPS: 0.5709\n",
      "Epoch [188/500], Loss: 2.0670723915100098, PSNR: 6.6885, SSIM: 0.0794, LPIPS: 0.5700\n",
      "Epoch [189/500], Loss: 2.0643105506896973, PSNR: 6.7058, SSIM: 0.0795, LPIPS: 0.5691\n",
      "Epoch [190/500], Loss: 2.061526298522949, PSNR: 6.7247, SSIM: 0.0794, LPIPS: 0.5682\n",
      "Epoch [191/500], Loss: 2.05855131149292, PSNR: 6.7417, SSIM: 0.0797, LPIPS: 0.5676\n",
      "Epoch [192/500], Loss: 2.0556766986846924, PSNR: 6.7596, SSIM: 0.0798, LPIPS: 0.5667\n",
      "Epoch [193/500], Loss: 2.053156852722168, PSNR: 6.7757, SSIM: 0.0800, LPIPS: 0.5660\n",
      "Epoch [194/500], Loss: 2.0501654148101807, PSNR: 6.7923, SSIM: 0.0803, LPIPS: 0.5652\n",
      "Epoch [195/500], Loss: 2.047290802001953, PSNR: 6.8102, SSIM: 0.0804, LPIPS: 0.5646\n",
      "Epoch [196/500], Loss: 2.0445990562438965, PSNR: 6.8287, SSIM: 0.0805, LPIPS: 0.5637\n",
      "Epoch [197/500], Loss: 2.0418176651000977, PSNR: 6.8468, SSIM: 0.0808, LPIPS: 0.5631\n",
      "Epoch [198/500], Loss: 2.039094924926758, PSNR: 6.8646, SSIM: 0.0811, LPIPS: 0.5624\n",
      "Epoch [199/500], Loss: 2.0365407466888428, PSNR: 6.8831, SSIM: 0.0814, LPIPS: 0.5616\n",
      "Epoch [200/500], Loss: 2.033806800842285, PSNR: 6.9016, SSIM: 0.0816, LPIPS: 0.5609\n",
      "Epoch [201/500], Loss: 2.0312392711639404, PSNR: 6.9204, SSIM: 0.0818, LPIPS: 0.5601\n",
      "Epoch [202/500], Loss: 2.0286381244659424, PSNR: 6.9394, SSIM: 0.0820, LPIPS: 0.5591\n",
      "Epoch [203/500], Loss: 2.0259616374969482, PSNR: 6.9571, SSIM: 0.0822, LPIPS: 0.5585\n",
      "Epoch [204/500], Loss: 2.023465633392334, PSNR: 6.9767, SSIM: 0.0824, LPIPS: 0.5577\n",
      "Epoch [205/500], Loss: 2.0212199687957764, PSNR: 6.9947, SSIM: 0.0827, LPIPS: 0.5570\n",
      "Epoch [206/500], Loss: 2.018491268157959, PSNR: 7.0150, SSIM: 0.0829, LPIPS: 0.5559\n",
      "Epoch [207/500], Loss: 2.016267776489258, PSNR: 7.0310, SSIM: 0.0835, LPIPS: 0.5556\n",
      "Epoch [208/500], Loss: 2.0134449005126953, PSNR: 7.0499, SSIM: 0.0838, LPIPS: 0.5546\n",
      "Epoch [209/500], Loss: 2.011453628540039, PSNR: 7.0699, SSIM: 0.0841, LPIPS: 0.5537\n",
      "Epoch [210/500], Loss: 2.0104527473449707, PSNR: 7.0843, SSIM: 0.0848, LPIPS: 0.5539\n",
      "Epoch [211/500], Loss: 2.006181001663208, PSNR: 7.1046, SSIM: 0.0850, LPIPS: 0.5524\n",
      "Epoch [212/500], Loss: 2.0064494609832764, PSNR: 7.1255, SSIM: 0.0850, LPIPS: 0.5512\n",
      "Epoch [213/500], Loss: 2.0027015209198, PSNR: 7.1378, SSIM: 0.0855, LPIPS: 0.5519\n",
      "Epoch [214/500], Loss: 2.00016713142395, PSNR: 7.1557, SSIM: 0.0859, LPIPS: 0.5511\n",
      "Epoch [215/500], Loss: 1.997796654701233, PSNR: 7.1781, SSIM: 0.0861, LPIPS: 0.5493\n",
      "Epoch [216/500], Loss: 1.994600534439087, PSNR: 7.1964, SSIM: 0.0864, LPIPS: 0.5493\n",
      "Epoch [217/500], Loss: 1.993287205696106, PSNR: 7.2116, SSIM: 0.0869, LPIPS: 0.5499\n",
      "Epoch [218/500], Loss: 1.989971399307251, PSNR: 7.2297, SSIM: 0.0873, LPIPS: 0.5484\n",
      "Epoch [219/500], Loss: 1.98860502243042, PSNR: 7.2494, SSIM: 0.0878, LPIPS: 0.5466\n",
      "Epoch [220/500], Loss: 1.9856154918670654, PSNR: 7.2645, SSIM: 0.0883, LPIPS: 0.5471\n",
      "Epoch [221/500], Loss: 1.9838157892227173, PSNR: 7.2822, SSIM: 0.0885, LPIPS: 0.5470\n",
      "Epoch [222/500], Loss: 1.9818369150161743, PSNR: 7.3019, SSIM: 0.0888, LPIPS: 0.5451\n",
      "Epoch [223/500], Loss: 1.9789670705795288, PSNR: 7.3154, SSIM: 0.0893, LPIPS: 0.5443\n",
      "Epoch [224/500], Loss: 1.9768171310424805, PSNR: 7.3317, SSIM: 0.0895, LPIPS: 0.5440\n",
      "Epoch [225/500], Loss: 1.974545955657959, PSNR: 7.3503, SSIM: 0.0897, LPIPS: 0.5432\n",
      "Epoch [226/500], Loss: 1.9726147651672363, PSNR: 7.3663, SSIM: 0.0901, LPIPS: 0.5421\n",
      "Epoch [227/500], Loss: 1.970846176147461, PSNR: 7.3779, SSIM: 0.0907, LPIPS: 0.5421\n",
      "Epoch [228/500], Loss: 1.9681947231292725, PSNR: 7.3959, SSIM: 0.0911, LPIPS: 0.5411\n",
      "Epoch [229/500], Loss: 1.96751070022583, PSNR: 7.4161, SSIM: 0.0914, LPIPS: 0.5396\n",
      "Epoch [230/500], Loss: 1.964102864265442, PSNR: 7.4280, SSIM: 0.0919, LPIPS: 0.5401\n",
      "Epoch [231/500], Loss: 1.9623594284057617, PSNR: 7.4419, SSIM: 0.0923, LPIPS: 0.5394\n",
      "Epoch [232/500], Loss: 1.9602018594741821, PSNR: 7.4602, SSIM: 0.0924, LPIPS: 0.5376\n",
      "Epoch [233/500], Loss: 1.9578368663787842, PSNR: 7.4754, SSIM: 0.0927, LPIPS: 0.5377\n",
      "Epoch [234/500], Loss: 1.9563618898391724, PSNR: 7.4899, SSIM: 0.0932, LPIPS: 0.5376\n",
      "Epoch [235/500], Loss: 1.9540354013442993, PSNR: 7.5071, SSIM: 0.0936, LPIPS: 0.5358\n",
      "Epoch [236/500], Loss: 1.9517513513565063, PSNR: 7.5215, SSIM: 0.0941, LPIPS: 0.5357\n",
      "Epoch [237/500], Loss: 1.9500117301940918, PSNR: 7.5363, SSIM: 0.0946, LPIPS: 0.5358\n",
      "Epoch [238/500], Loss: 1.948081612586975, PSNR: 7.5537, SSIM: 0.0950, LPIPS: 0.5344\n",
      "Epoch [239/500], Loss: 1.9461040496826172, PSNR: 7.5677, SSIM: 0.0955, LPIPS: 0.5344\n",
      "Epoch [240/500], Loss: 1.9442055225372314, PSNR: 7.5855, SSIM: 0.0960, LPIPS: 0.5333\n",
      "Epoch [241/500], Loss: 1.9419869184494019, PSNR: 7.5995, SSIM: 0.0964, LPIPS: 0.5333\n",
      "Epoch [242/500], Loss: 1.939800500869751, PSNR: 7.6166, SSIM: 0.0968, LPIPS: 0.5322\n",
      "Epoch [243/500], Loss: 1.9378890991210938, PSNR: 7.6302, SSIM: 0.0974, LPIPS: 0.5323\n",
      "Epoch [244/500], Loss: 1.936099886894226, PSNR: 7.6470, SSIM: 0.0978, LPIPS: 0.5309\n",
      "Epoch [245/500], Loss: 1.9342721700668335, PSNR: 7.6593, SSIM: 0.0982, LPIPS: 0.5315\n",
      "Epoch [246/500], Loss: 1.9322952032089233, PSNR: 7.6765, SSIM: 0.0988, LPIPS: 0.5298\n",
      "Epoch [247/500], Loss: 1.9301555156707764, PSNR: 7.6897, SSIM: 0.0991, LPIPS: 0.5296\n",
      "Epoch [248/500], Loss: 1.9278759956359863, PSNR: 7.7049, SSIM: 0.0995, LPIPS: 0.5296\n",
      "Epoch [249/500], Loss: 1.9260741472244263, PSNR: 7.7207, SSIM: 0.0999, LPIPS: 0.5289\n",
      "Epoch [250/500], Loss: 1.925020456314087, PSNR: 7.7315, SSIM: 0.1004, LPIPS: 0.5289\n",
      "Epoch [251/500], Loss: 1.9228774309158325, PSNR: 7.7486, SSIM: 0.1011, LPIPS: 0.5270\n",
      "Epoch [252/500], Loss: 1.9208084344863892, PSNR: 7.7628, SSIM: 0.1012, LPIPS: 0.5267\n",
      "Epoch [253/500], Loss: 1.918975830078125, PSNR: 7.7747, SSIM: 0.1017, LPIPS: 0.5275\n",
      "Epoch [254/500], Loss: 1.9173871278762817, PSNR: 7.7922, SSIM: 0.1024, LPIPS: 0.5255\n",
      "Epoch [255/500], Loss: 1.9150164127349854, PSNR: 7.8048, SSIM: 0.1027, LPIPS: 0.5255\n",
      "Epoch [256/500], Loss: 1.9128212928771973, PSNR: 7.8189, SSIM: 0.1031, LPIPS: 0.5255\n",
      "Epoch [257/500], Loss: 1.911863088607788, PSNR: 7.8360, SSIM: 0.1037, LPIPS: 0.5242\n",
      "Epoch [258/500], Loss: 1.909329891204834, PSNR: 7.8482, SSIM: 0.1040, LPIPS: 0.5242\n",
      "Epoch [259/500], Loss: 1.9070338010787964, PSNR: 7.8631, SSIM: 0.1045, LPIPS: 0.5239\n",
      "Epoch [260/500], Loss: 1.9055496454238892, PSNR: 7.8795, SSIM: 0.1052, LPIPS: 0.5231\n",
      "Epoch [261/500], Loss: 1.9030364751815796, PSNR: 7.8912, SSIM: 0.1056, LPIPS: 0.5230\n",
      "Epoch [262/500], Loss: 1.9013392925262451, PSNR: 7.9052, SSIM: 0.1060, LPIPS: 0.5220\n",
      "Epoch [263/500], Loss: 1.8992671966552734, PSNR: 7.9208, SSIM: 0.1065, LPIPS: 0.5212\n",
      "Epoch [264/500], Loss: 1.8979368209838867, PSNR: 7.9329, SSIM: 0.1069, LPIPS: 0.5221\n",
      "Epoch [265/500], Loss: 1.8955568075180054, PSNR: 7.9481, SSIM: 0.1074, LPIPS: 0.5203\n",
      "Epoch [266/500], Loss: 1.8934264183044434, PSNR: 7.9606, SSIM: 0.1076, LPIPS: 0.5200\n",
      "Epoch [267/500], Loss: 1.8916661739349365, PSNR: 7.9757, SSIM: 0.1079, LPIPS: 0.5195\n",
      "Epoch [268/500], Loss: 1.889379858970642, PSNR: 7.9898, SSIM: 0.1085, LPIPS: 0.5192\n",
      "Epoch [269/500], Loss: 1.8875991106033325, PSNR: 8.0045, SSIM: 0.1089, LPIPS: 0.5186\n",
      "Epoch [270/500], Loss: 1.8857797384262085, PSNR: 8.0187, SSIM: 0.1093, LPIPS: 0.5183\n",
      "Epoch [271/500], Loss: 1.8837648630142212, PSNR: 8.0335, SSIM: 0.1096, LPIPS: 0.5180\n",
      "Epoch [272/500], Loss: 1.882049322128296, PSNR: 8.0492, SSIM: 0.1102, LPIPS: 0.5171\n",
      "Epoch [273/500], Loss: 1.8805146217346191, PSNR: 8.0629, SSIM: 0.1107, LPIPS: 0.5173\n",
      "Epoch [274/500], Loss: 1.878633737564087, PSNR: 8.0793, SSIM: 0.1112, LPIPS: 0.5162\n",
      "Epoch [275/500], Loss: 1.8771445751190186, PSNR: 8.0915, SSIM: 0.1116, LPIPS: 0.5167\n",
      "Epoch [276/500], Loss: 1.8752577304840088, PSNR: 8.1089, SSIM: 0.1121, LPIPS: 0.5155\n",
      "Epoch [277/500], Loss: 1.8742766380310059, PSNR: 8.1202, SSIM: 0.1126, LPIPS: 0.5164\n",
      "Epoch [278/500], Loss: 1.8737140893936157, PSNR: 8.1405, SSIM: 0.1134, LPIPS: 0.5141\n",
      "Epoch [279/500], Loss: 1.8722405433654785, PSNR: 8.1469, SSIM: 0.1136, LPIPS: 0.5162\n",
      "Epoch [280/500], Loss: 1.8687214851379395, PSNR: 8.1656, SSIM: 0.1141, LPIPS: 0.5137\n",
      "Epoch [281/500], Loss: 1.8666070699691772, PSNR: 8.1772, SSIM: 0.1145, LPIPS: 0.5138\n",
      "Epoch [282/500], Loss: 1.8661504983901978, PSNR: 8.1852, SSIM: 0.1149, LPIPS: 0.5146\n",
      "Epoch [283/500], Loss: 1.8650435209274292, PSNR: 8.2039, SSIM: 0.1155, LPIPS: 0.5119\n",
      "Epoch [284/500], Loss: 1.8638348579406738, PSNR: 8.2115, SSIM: 0.1155, LPIPS: 0.5136\n",
      "Epoch [285/500], Loss: 1.8601630926132202, PSNR: 8.2275, SSIM: 0.1163, LPIPS: 0.5119\n",
      "Epoch [286/500], Loss: 1.858785629272461, PSNR: 8.2381, SSIM: 0.1168, LPIPS: 0.5115\n",
      "Epoch [287/500], Loss: 1.858084797859192, PSNR: 8.2465, SSIM: 0.1168, LPIPS: 0.5118\n",
      "Epoch [288/500], Loss: 1.8559989929199219, PSNR: 8.2626, SSIM: 0.1175, LPIPS: 0.5097\n",
      "Epoch [289/500], Loss: 1.8540377616882324, PSNR: 8.2688, SSIM: 0.1178, LPIPS: 0.5103\n",
      "Epoch [290/500], Loss: 1.8518180847167969, PSNR: 8.2815, SSIM: 0.1182, LPIPS: 0.5092\n",
      "Epoch [291/500], Loss: 1.8504438400268555, PSNR: 8.2954, SSIM: 0.1187, LPIPS: 0.5087\n",
      "Epoch [292/500], Loss: 1.8491781949996948, PSNR: 8.3047, SSIM: 0.1191, LPIPS: 0.5091\n",
      "Epoch [293/500], Loss: 1.8478695154190063, PSNR: 8.3223, SSIM: 0.1196, LPIPS: 0.5071\n",
      "Epoch [294/500], Loss: 1.8465101718902588, PSNR: 8.3295, SSIM: 0.1201, LPIPS: 0.5086\n",
      "Epoch [295/500], Loss: 1.8440274000167847, PSNR: 8.3474, SSIM: 0.1206, LPIPS: 0.5070\n",
      "Epoch [296/500], Loss: 1.8424937725067139, PSNR: 8.3575, SSIM: 0.1209, LPIPS: 0.5072\n",
      "Epoch [297/500], Loss: 1.8409312963485718, PSNR: 8.3715, SSIM: 0.1215, LPIPS: 0.5065\n",
      "Epoch [298/500], Loss: 1.8393279314041138, PSNR: 8.3818, SSIM: 0.1218, LPIPS: 0.5063\n",
      "Epoch [299/500], Loss: 1.8377987146377563, PSNR: 8.3946, SSIM: 0.1223, LPIPS: 0.5054\n",
      "Epoch [300/500], Loss: 1.8369965553283691, PSNR: 8.4033, SSIM: 0.1228, LPIPS: 0.5060\n",
      "Epoch [301/500], Loss: 1.8373785018920898, PSNR: 8.4218, SSIM: 0.1232, LPIPS: 0.5037\n",
      "Epoch [302/500], Loss: 1.8376104831695557, PSNR: 8.4225, SSIM: 0.1234, LPIPS: 0.5063\n",
      "Epoch [303/500], Loss: 1.8345006704330444, PSNR: 8.4440, SSIM: 0.1244, LPIPS: 0.5028\n",
      "Epoch [304/500], Loss: 1.8316762447357178, PSNR: 8.4520, SSIM: 0.1242, LPIPS: 0.5039\n",
      "Epoch [305/500], Loss: 1.830507755279541, PSNR: 8.4603, SSIM: 0.1247, LPIPS: 0.5047\n",
      "Epoch [306/500], Loss: 1.8308852910995483, PSNR: 8.4787, SSIM: 0.1255, LPIPS: 0.5017\n",
      "Epoch [307/500], Loss: 1.8276957273483276, PSNR: 8.4833, SSIM: 0.1256, LPIPS: 0.5032\n",
      "Epoch [308/500], Loss: 1.8255223035812378, PSNR: 8.4968, SSIM: 0.1262, LPIPS: 0.5028\n",
      "Epoch [309/500], Loss: 1.8252928256988525, PSNR: 8.5129, SSIM: 0.1270, LPIPS: 0.5009\n",
      "Epoch [310/500], Loss: 1.8242051601409912, PSNR: 8.5174, SSIM: 0.1272, LPIPS: 0.5025\n",
      "Epoch [311/500], Loss: 1.821526288986206, PSNR: 8.5353, SSIM: 0.1276, LPIPS: 0.5003\n",
      "Epoch [312/500], Loss: 1.8206710815429688, PSNR: 8.5464, SSIM: 0.1281, LPIPS: 0.5001\n",
      "Epoch [313/500], Loss: 1.8209810256958008, PSNR: 8.5479, SSIM: 0.1283, LPIPS: 0.5019\n",
      "Epoch [314/500], Loss: 1.8185368776321411, PSNR: 8.5679, SSIM: 0.1290, LPIPS: 0.4987\n",
      "Epoch [315/500], Loss: 1.8160018920898438, PSNR: 8.5775, SSIM: 0.1291, LPIPS: 0.5000\n",
      "Epoch [316/500], Loss: 1.8164100646972656, PSNR: 8.5827, SSIM: 0.1293, LPIPS: 0.5013\n",
      "Epoch [317/500], Loss: 1.816391944885254, PSNR: 8.6018, SSIM: 0.1303, LPIPS: 0.4976\n",
      "Epoch [318/500], Loss: 1.8131569623947144, PSNR: 8.6035, SSIM: 0.1304, LPIPS: 0.4997\n",
      "Epoch [319/500], Loss: 1.8107818365097046, PSNR: 8.6170, SSIM: 0.1308, LPIPS: 0.4991\n",
      "Epoch [320/500], Loss: 1.811718463897705, PSNR: 8.6327, SSIM: 0.1313, LPIPS: 0.4971\n",
      "Epoch [321/500], Loss: 1.8104469776153564, PSNR: 8.6336, SSIM: 0.1315, LPIPS: 0.4989\n",
      "Epoch [322/500], Loss: 1.8077521324157715, PSNR: 8.6505, SSIM: 0.1322, LPIPS: 0.4967\n",
      "Epoch [323/500], Loss: 1.8065567016601562, PSNR: 8.6624, SSIM: 0.1324, LPIPS: 0.4961\n",
      "Epoch [324/500], Loss: 1.8054494857788086, PSNR: 8.6673, SSIM: 0.1327, LPIPS: 0.4980\n",
      "Epoch [325/500], Loss: 1.8036727905273438, PSNR: 8.6812, SSIM: 0.1334, LPIPS: 0.4960\n",
      "Epoch [326/500], Loss: 1.8028719425201416, PSNR: 8.6927, SSIM: 0.1334, LPIPS: 0.4950\n",
      "Epoch [327/500], Loss: 1.8010342121124268, PSNR: 8.7006, SSIM: 0.1338, LPIPS: 0.4960\n",
      "Epoch [328/500], Loss: 1.8006205558776855, PSNR: 8.7149, SSIM: 0.1347, LPIPS: 0.4943\n",
      "Epoch [329/500], Loss: 1.7989976406097412, PSNR: 8.7209, SSIM: 0.1347, LPIPS: 0.4945\n",
      "Epoch [330/500], Loss: 1.7969032526016235, PSNR: 8.7329, SSIM: 0.1351, LPIPS: 0.4938\n",
      "Epoch [331/500], Loss: 1.7964081764221191, PSNR: 8.7428, SSIM: 0.1356, LPIPS: 0.4936\n",
      "Epoch [332/500], Loss: 1.795081377029419, PSNR: 8.7491, SSIM: 0.1358, LPIPS: 0.4932\n",
      "Epoch [333/500], Loss: 1.7939776182174683, PSNR: 8.7636, SSIM: 0.1363, LPIPS: 0.4914\n",
      "Epoch [334/500], Loss: 1.7942897081375122, PSNR: 8.7680, SSIM: 0.1368, LPIPS: 0.4932\n",
      "Epoch [335/500], Loss: 1.7923085689544678, PSNR: 8.7850, SSIM: 0.1371, LPIPS: 0.4900\n",
      "Epoch [336/500], Loss: 1.790299654006958, PSNR: 8.7901, SSIM: 0.1373, LPIPS: 0.4916\n",
      "Epoch [337/500], Loss: 1.7888761758804321, PSNR: 8.8030, SSIM: 0.1379, LPIPS: 0.4909\n",
      "Epoch [338/500], Loss: 1.7882940769195557, PSNR: 8.8157, SSIM: 0.1383, LPIPS: 0.4898\n",
      "Epoch [339/500], Loss: 1.7882194519042969, PSNR: 8.8194, SSIM: 0.1385, LPIPS: 0.4920\n",
      "Epoch [340/500], Loss: 1.786649227142334, PSNR: 8.8385, SSIM: 0.1391, LPIPS: 0.4893\n",
      "Epoch [341/500], Loss: 1.7843079566955566, PSNR: 8.8438, SSIM: 0.1393, LPIPS: 0.4896\n",
      "Epoch [342/500], Loss: 1.7825407981872559, PSNR: 8.8542, SSIM: 0.1397, LPIPS: 0.4892\n",
      "Epoch [343/500], Loss: 1.7827763557434082, PSNR: 8.8689, SSIM: 0.1402, LPIPS: 0.4879\n",
      "Epoch [344/500], Loss: 1.7814452648162842, PSNR: 8.8735, SSIM: 0.1404, LPIPS: 0.4893\n",
      "Epoch [345/500], Loss: 1.779940128326416, PSNR: 8.8906, SSIM: 0.1408, LPIPS: 0.4870\n",
      "Epoch [346/500], Loss: 1.7783050537109375, PSNR: 8.8970, SSIM: 0.1410, LPIPS: 0.4886\n",
      "Epoch [347/500], Loss: 1.7769299745559692, PSNR: 8.9079, SSIM: 0.1415, LPIPS: 0.4882\n",
      "Epoch [348/500], Loss: 1.776241660118103, PSNR: 8.9234, SSIM: 0.1419, LPIPS: 0.4866\n",
      "Epoch [349/500], Loss: 1.7752442359924316, PSNR: 8.9283, SSIM: 0.1420, LPIPS: 0.4878\n",
      "Epoch [350/500], Loss: 1.773525595664978, PSNR: 8.9431, SSIM: 0.1424, LPIPS: 0.4860\n",
      "Epoch [351/500], Loss: 1.772099494934082, PSNR: 8.9523, SSIM: 0.1430, LPIPS: 0.4860\n",
      "Epoch [352/500], Loss: 1.7711832523345947, PSNR: 8.9604, SSIM: 0.1432, LPIPS: 0.4862\n",
      "Epoch [353/500], Loss: 1.7702503204345703, PSNR: 8.9741, SSIM: 0.1437, LPIPS: 0.4846\n",
      "Epoch [354/500], Loss: 1.7696633338928223, PSNR: 8.9809, SSIM: 0.1439, LPIPS: 0.4852\n",
      "Epoch [355/500], Loss: 1.768131971359253, PSNR: 8.9965, SSIM: 0.1444, LPIPS: 0.4836\n",
      "Epoch [356/500], Loss: 1.7673910856246948, PSNR: 9.0002, SSIM: 0.1445, LPIPS: 0.4853\n",
      "Epoch [357/500], Loss: 1.7658922672271729, PSNR: 9.0151, SSIM: 0.1449, LPIPS: 0.4832\n",
      "Epoch [358/500], Loss: 1.7644107341766357, PSNR: 9.0216, SSIM: 0.1450, LPIPS: 0.4838\n",
      "Epoch [359/500], Loss: 1.7630248069763184, PSNR: 9.0333, SSIM: 0.1453, LPIPS: 0.4827\n",
      "Epoch [360/500], Loss: 1.7618829011917114, PSNR: 9.0436, SSIM: 0.1457, LPIPS: 0.4820\n",
      "Epoch [361/500], Loss: 1.7611420154571533, PSNR: 9.0494, SSIM: 0.1459, LPIPS: 0.4828\n",
      "Epoch [362/500], Loss: 1.76116144657135, PSNR: 9.0635, SSIM: 0.1461, LPIPS: 0.4810\n",
      "Epoch [363/500], Loss: 1.7620165348052979, PSNR: 9.0628, SSIM: 0.1462, LPIPS: 0.4837\n",
      "Epoch [364/500], Loss: 1.7608968019485474, PSNR: 9.0811, SSIM: 0.1470, LPIPS: 0.4802\n",
      "Epoch [365/500], Loss: 1.758040428161621, PSNR: 9.0837, SSIM: 0.1467, LPIPS: 0.4815\n",
      "Epoch [366/500], Loss: 1.7557872533798218, PSNR: 9.0939, SSIM: 0.1472, LPIPS: 0.4813\n",
      "Epoch [367/500], Loss: 1.7566759586334229, PSNR: 9.1089, SSIM: 0.1478, LPIPS: 0.4791\n",
      "Epoch [368/500], Loss: 1.7555205821990967, PSNR: 9.1093, SSIM: 0.1476, LPIPS: 0.4813\n",
      "Epoch [369/500], Loss: 1.7532013654708862, PSNR: 9.1236, SSIM: 0.1480, LPIPS: 0.4791\n",
      "Epoch [370/500], Loss: 1.7511759996414185, PSNR: 9.1307, SSIM: 0.1482, LPIPS: 0.4789\n",
      "Epoch [371/500], Loss: 1.7519359588623047, PSNR: 9.1347, SSIM: 0.1482, LPIPS: 0.4803\n",
      "Epoch [372/500], Loss: 1.7505651712417603, PSNR: 9.1522, SSIM: 0.1488, LPIPS: 0.4780\n",
      "Epoch [373/500], Loss: 1.747948169708252, PSNR: 9.1578, SSIM: 0.1492, LPIPS: 0.4788\n",
      "Epoch [374/500], Loss: 1.7468101978302002, PSNR: 9.1665, SSIM: 0.1496, LPIPS: 0.4785\n",
      "Epoch [375/500], Loss: 1.7465895414352417, PSNR: 9.1810, SSIM: 0.1499, LPIPS: 0.4770\n",
      "Epoch [376/500], Loss: 1.7458784580230713, PSNR: 9.1872, SSIM: 0.1497, LPIPS: 0.4778\n",
      "Epoch [377/500], Loss: 1.7436904907226562, PSNR: 9.1987, SSIM: 0.1504, LPIPS: 0.4772\n",
      "Epoch [378/500], Loss: 1.742523431777954, PSNR: 9.2076, SSIM: 0.1507, LPIPS: 0.4766\n",
      "Epoch [379/500], Loss: 1.7414730787277222, PSNR: 9.2150, SSIM: 0.1507, LPIPS: 0.4767\n",
      "Epoch [380/500], Loss: 1.7410463094711304, PSNR: 9.2247, SSIM: 0.1510, LPIPS: 0.4764\n",
      "Epoch [381/500], Loss: 1.739104986190796, PSNR: 9.2301, SSIM: 0.1512, LPIPS: 0.4764\n",
      "Epoch [382/500], Loss: 1.7381480932235718, PSNR: 9.2383, SSIM: 0.1515, LPIPS: 0.4762\n",
      "Epoch [383/500], Loss: 1.737562656402588, PSNR: 9.2470, SSIM: 0.1518, LPIPS: 0.4758\n",
      "Epoch [384/500], Loss: 1.7361003160476685, PSNR: 9.2556, SSIM: 0.1518, LPIPS: 0.4748\n",
      "Epoch [385/500], Loss: 1.7349157333374023, PSNR: 9.2652, SSIM: 0.1525, LPIPS: 0.4742\n",
      "Epoch [386/500], Loss: 1.7340768575668335, PSNR: 9.2730, SSIM: 0.1527, LPIPS: 0.4742\n",
      "Epoch [387/500], Loss: 1.7329602241516113, PSNR: 9.2778, SSIM: 0.1525, LPIPS: 0.4739\n",
      "Epoch [388/500], Loss: 1.7314057350158691, PSNR: 9.2876, SSIM: 0.1529, LPIPS: 0.4732\n",
      "Epoch [389/500], Loss: 1.7306902408599854, PSNR: 9.2959, SSIM: 0.1531, LPIPS: 0.4732\n",
      "Epoch [390/500], Loss: 1.7297167778015137, PSNR: 9.3029, SSIM: 0.1532, LPIPS: 0.4733\n",
      "Epoch [391/500], Loss: 1.7290353775024414, PSNR: 9.3167, SSIM: 0.1537, LPIPS: 0.4724\n",
      "Epoch [392/500], Loss: 1.7280181646347046, PSNR: 9.3207, SSIM: 0.1539, LPIPS: 0.4736\n",
      "Epoch [393/500], Loss: 1.7274703979492188, PSNR: 9.3325, SSIM: 0.1539, LPIPS: 0.4718\n",
      "Epoch [394/500], Loss: 1.725823998451233, PSNR: 9.3402, SSIM: 0.1546, LPIPS: 0.4718\n",
      "Epoch [395/500], Loss: 1.7241102457046509, PSNR: 9.3493, SSIM: 0.1547, LPIPS: 0.4713\n",
      "Epoch [396/500], Loss: 1.723460078239441, PSNR: 9.3572, SSIM: 0.1547, LPIPS: 0.4716\n",
      "Epoch [397/500], Loss: 1.722477674484253, PSNR: 9.3683, SSIM: 0.1554, LPIPS: 0.4713\n",
      "Epoch [398/500], Loss: 1.7214043140411377, PSNR: 9.3770, SSIM: 0.1553, LPIPS: 0.4708\n",
      "Epoch [399/500], Loss: 1.7201054096221924, PSNR: 9.3837, SSIM: 0.1556, LPIPS: 0.4711\n",
      "Epoch [400/500], Loss: 1.7191768884658813, PSNR: 9.3937, SSIM: 0.1560, LPIPS: 0.4702\n",
      "Epoch [401/500], Loss: 1.7186064720153809, PSNR: 9.3991, SSIM: 0.1559, LPIPS: 0.4703\n",
      "Epoch [402/500], Loss: 1.7180930376052856, PSNR: 9.4108, SSIM: 0.1563, LPIPS: 0.4699\n",
      "Epoch [403/500], Loss: 1.71759033203125, PSNR: 9.4147, SSIM: 0.1564, LPIPS: 0.4707\n",
      "Epoch [404/500], Loss: 1.7191414833068848, PSNR: 9.4311, SSIM: 0.1567, LPIPS: 0.4688\n",
      "Epoch [405/500], Loss: 1.719029188156128, PSNR: 9.4282, SSIM: 0.1568, LPIPS: 0.4722\n",
      "Epoch [406/500], Loss: 1.7156598567962646, PSNR: 9.4457, SSIM: 0.1570, LPIPS: 0.4686\n",
      "Epoch [407/500], Loss: 1.7127667665481567, PSNR: 9.4494, SSIM: 0.1574, LPIPS: 0.4691\n",
      "Epoch [408/500], Loss: 1.712539553642273, PSNR: 9.4570, SSIM: 0.1576, LPIPS: 0.4695\n",
      "Epoch [409/500], Loss: 1.712235450744629, PSNR: 9.4690, SSIM: 0.1577, LPIPS: 0.4680\n",
      "Epoch [410/500], Loss: 1.711087703704834, PSNR: 9.4701, SSIM: 0.1580, LPIPS: 0.4695\n",
      "Epoch [411/500], Loss: 1.7094060182571411, PSNR: 9.4838, SSIM: 0.1583, LPIPS: 0.4680\n",
      "Epoch [412/500], Loss: 1.7088621854782104, PSNR: 9.4870, SSIM: 0.1582, LPIPS: 0.4689\n",
      "Epoch [413/500], Loss: 1.707846999168396, PSNR: 9.4969, SSIM: 0.1588, LPIPS: 0.4681\n",
      "Epoch [414/500], Loss: 1.7060190439224243, PSNR: 9.5028, SSIM: 0.1588, LPIPS: 0.4678\n",
      "Epoch [415/500], Loss: 1.7054097652435303, PSNR: 9.5097, SSIM: 0.1590, LPIPS: 0.4679\n",
      "Epoch [416/500], Loss: 1.7049058675765991, PSNR: 9.5209, SSIM: 0.1595, LPIPS: 0.4667\n",
      "Epoch [417/500], Loss: 1.7047510147094727, PSNR: 9.5242, SSIM: 0.1595, LPIPS: 0.4672\n",
      "Epoch [418/500], Loss: 1.7046070098876953, PSNR: 9.5389, SSIM: 0.1598, LPIPS: 0.4660\n",
      "Epoch [419/500], Loss: 1.7058539390563965, PSNR: 9.5357, SSIM: 0.1598, LPIPS: 0.4686\n",
      "Epoch [420/500], Loss: 1.7051668167114258, PSNR: 9.5533, SSIM: 0.1600, LPIPS: 0.4651\n",
      "Epoch [421/500], Loss: 1.7018821239471436, PSNR: 9.5525, SSIM: 0.1601, LPIPS: 0.4671\n",
      "Epoch [422/500], Loss: 1.6994539499282837, PSNR: 9.5640, SSIM: 0.1605, LPIPS: 0.4658\n",
      "Epoch [423/500], Loss: 1.7004505395889282, PSNR: 9.5748, SSIM: 0.1606, LPIPS: 0.4650\n",
      "Epoch [424/500], Loss: 1.6998398303985596, PSNR: 9.5773, SSIM: 0.1610, LPIPS: 0.4670\n",
      "Epoch [425/500], Loss: 1.6972229480743408, PSNR: 9.5897, SSIM: 0.1612, LPIPS: 0.4649\n",
      "Epoch [426/500], Loss: 1.6968433856964111, PSNR: 9.5948, SSIM: 0.1612, LPIPS: 0.4649\n",
      "Epoch [427/500], Loss: 1.697728157043457, PSNR: 9.6003, SSIM: 0.1616, LPIPS: 0.4660\n",
      "Epoch [428/500], Loss: 1.6950974464416504, PSNR: 9.6108, SSIM: 0.1616, LPIPS: 0.4644\n",
      "Epoch [429/500], Loss: 1.694779634475708, PSNR: 9.6129, SSIM: 0.1616, LPIPS: 0.4648\n",
      "Epoch [430/500], Loss: 1.6943153142929077, PSNR: 9.6268, SSIM: 0.1624, LPIPS: 0.4640\n",
      "Epoch [431/500], Loss: 1.6925122737884521, PSNR: 9.6325, SSIM: 0.1623, LPIPS: 0.4643\n",
      "Epoch [432/500], Loss: 1.6914266347885132, PSNR: 9.6372, SSIM: 0.1625, LPIPS: 0.4641\n",
      "Epoch [433/500], Loss: 1.6917109489440918, PSNR: 9.6482, SSIM: 0.1630, LPIPS: 0.4634\n",
      "Epoch [434/500], Loss: 1.6900516748428345, PSNR: 9.6499, SSIM: 0.1628, LPIPS: 0.4646\n",
      "Epoch [435/500], Loss: 1.691016674041748, PSNR: 9.6620, SSIM: 0.1631, LPIPS: 0.4624\n",
      "Epoch [436/500], Loss: 1.6919012069702148, PSNR: 9.6642, SSIM: 0.1635, LPIPS: 0.4644\n",
      "Epoch [437/500], Loss: 1.6897389888763428, PSNR: 9.6783, SSIM: 0.1634, LPIPS: 0.4618\n",
      "Epoch [438/500], Loss: 1.688690423965454, PSNR: 9.6764, SSIM: 0.1632, LPIPS: 0.4634\n",
      "Epoch [439/500], Loss: 1.6864687204360962, PSNR: 9.6925, SSIM: 0.1641, LPIPS: 0.4618\n",
      "Epoch [440/500], Loss: 1.6849602460861206, PSNR: 9.6995, SSIM: 0.1644, LPIPS: 0.4616\n",
      "Epoch [441/500], Loss: 1.686509370803833, PSNR: 9.6994, SSIM: 0.1640, LPIPS: 0.4631\n",
      "Epoch [442/500], Loss: 1.6877378225326538, PSNR: 9.7180, SSIM: 0.1646, LPIPS: 0.4600\n",
      "Epoch [443/500], Loss: 1.6883798837661743, PSNR: 9.7121, SSIM: 0.1645, LPIPS: 0.4635\n",
      "Epoch [444/500], Loss: 1.6836791038513184, PSNR: 9.7255, SSIM: 0.1646, LPIPS: 0.4604\n",
      "Epoch [445/500], Loss: 1.6817421913146973, PSNR: 9.7295, SSIM: 0.1648, LPIPS: 0.4610\n",
      "Epoch [446/500], Loss: 1.6822395324707031, PSNR: 9.7365, SSIM: 0.1651, LPIPS: 0.4618\n",
      "Epoch [447/500], Loss: 1.682410717010498, PSNR: 9.7532, SSIM: 0.1654, LPIPS: 0.4590\n",
      "Epoch [448/500], Loss: 1.6793568134307861, PSNR: 9.7494, SSIM: 0.1653, LPIPS: 0.4610\n",
      "Epoch [449/500], Loss: 1.6791025400161743, PSNR: 9.7545, SSIM: 0.1656, LPIPS: 0.4607\n",
      "Epoch [450/500], Loss: 1.6788924932479858, PSNR: 9.7669, SSIM: 0.1658, LPIPS: 0.4587\n",
      "Epoch [451/500], Loss: 1.6772011518478394, PSNR: 9.7691, SSIM: 0.1657, LPIPS: 0.4604\n",
      "Epoch [452/500], Loss: 1.6766421794891357, PSNR: 9.7769, SSIM: 0.1660, LPIPS: 0.4599\n",
      "Epoch [453/500], Loss: 1.6761234998703003, PSNR: 9.7855, SSIM: 0.1663, LPIPS: 0.4587\n",
      "Epoch [454/500], Loss: 1.675746202468872, PSNR: 9.7919, SSIM: 0.1666, LPIPS: 0.4594\n",
      "Epoch [455/500], Loss: 1.6741828918457031, PSNR: 9.7993, SSIM: 0.1667, LPIPS: 0.4583\n",
      "Epoch [456/500], Loss: 1.6734144687652588, PSNR: 9.7998, SSIM: 0.1665, LPIPS: 0.4582\n",
      "Epoch [457/500], Loss: 1.6724629402160645, PSNR: 9.8078, SSIM: 0.1670, LPIPS: 0.4582\n",
      "Epoch [458/500], Loss: 1.6712381839752197, PSNR: 9.8189, SSIM: 0.1673, LPIPS: 0.4576\n",
      "Epoch [459/500], Loss: 1.67179536819458, PSNR: 9.8214, SSIM: 0.1670, LPIPS: 0.4583\n",
      "Epoch [460/500], Loss: 1.6700167655944824, PSNR: 9.8316, SSIM: 0.1676, LPIPS: 0.4573\n",
      "Epoch [461/500], Loss: 1.6697083711624146, PSNR: 9.8330, SSIM: 0.1677, LPIPS: 0.4575\n",
      "Epoch [462/500], Loss: 1.668705701828003, PSNR: 9.8421, SSIM: 0.1677, LPIPS: 0.4567\n",
      "Epoch [463/500], Loss: 1.6686193943023682, PSNR: 9.8472, SSIM: 0.1678, LPIPS: 0.4578\n",
      "Epoch [464/500], Loss: 1.6676387786865234, PSNR: 9.8583, SSIM: 0.1682, LPIPS: 0.4556\n",
      "Epoch [465/500], Loss: 1.6684794425964355, PSNR: 9.8549, SSIM: 0.1680, LPIPS: 0.4579\n",
      "Epoch [466/500], Loss: 1.6672804355621338, PSNR: 9.8694, SSIM: 0.1684, LPIPS: 0.4556\n",
      "Epoch [467/500], Loss: 1.6661124229431152, PSNR: 9.8689, SSIM: 0.1684, LPIPS: 0.4569\n",
      "Epoch [468/500], Loss: 1.6644401550292969, PSNR: 9.8810, SSIM: 0.1686, LPIPS: 0.4554\n",
      "Epoch [469/500], Loss: 1.6635290384292603, PSNR: 9.8839, SSIM: 0.1688, LPIPS: 0.4560\n",
      "Epoch [470/500], Loss: 1.6626454591751099, PSNR: 9.8863, SSIM: 0.1687, LPIPS: 0.4564\n",
      "Epoch [471/500], Loss: 1.6627036333084106, PSNR: 9.8985, SSIM: 0.1689, LPIPS: 0.4553\n",
      "Epoch [472/500], Loss: 1.663478136062622, PSNR: 9.9005, SSIM: 0.1691, LPIPS: 0.4566\n",
      "Epoch [473/500], Loss: 1.662947654724121, PSNR: 9.9121, SSIM: 0.1693, LPIPS: 0.4541\n",
      "Epoch [474/500], Loss: 1.6614899635314941, PSNR: 9.9074, SSIM: 0.1691, LPIPS: 0.4558\n",
      "Epoch [475/500], Loss: 1.6597728729248047, PSNR: 9.9230, SSIM: 0.1696, LPIPS: 0.4544\n",
      "Epoch [476/500], Loss: 1.6588246822357178, PSNR: 9.9320, SSIM: 0.1699, LPIPS: 0.4540\n",
      "Epoch [477/500], Loss: 1.659088134765625, PSNR: 9.9314, SSIM: 0.1699, LPIPS: 0.4552\n",
      "Epoch [478/500], Loss: 1.6591322422027588, PSNR: 9.9422, SSIM: 0.1701, LPIPS: 0.4538\n",
      "Epoch [479/500], Loss: 1.657745122909546, PSNR: 9.9418, SSIM: 0.1701, LPIPS: 0.4548\n",
      "Epoch [480/500], Loss: 1.6571455001831055, PSNR: 9.9528, SSIM: 0.1702, LPIPS: 0.4530\n",
      "Epoch [481/500], Loss: 1.6558836698532104, PSNR: 9.9539, SSIM: 0.1703, LPIPS: 0.4540\n",
      "Epoch [482/500], Loss: 1.654388189315796, PSNR: 9.9623, SSIM: 0.1704, LPIPS: 0.4533\n",
      "Epoch [483/500], Loss: 1.6542613506317139, PSNR: 9.9713, SSIM: 0.1708, LPIPS: 0.4524\n",
      "Epoch [484/500], Loss: 1.6539795398712158, PSNR: 9.9729, SSIM: 0.1710, LPIPS: 0.4533\n",
      "Epoch [485/500], Loss: 1.6541591882705688, PSNR: 9.9814, SSIM: 0.1710, LPIPS: 0.4524\n",
      "Epoch [486/500], Loss: 1.6531308889389038, PSNR: 9.9841, SSIM: 0.1712, LPIPS: 0.4535\n",
      "Epoch [487/500], Loss: 1.653233289718628, PSNR: 9.9973, SSIM: 0.1714, LPIPS: 0.4517\n",
      "Epoch [488/500], Loss: 1.6532409191131592, PSNR: 9.9897, SSIM: 0.1710, LPIPS: 0.4539\n",
      "Epoch [489/500], Loss: 1.6523970365524292, PSNR: 10.0043, SSIM: 0.1713, LPIPS: 0.4514\n",
      "Epoch [490/500], Loss: 1.6518027782440186, PSNR: 10.0041, SSIM: 0.1716, LPIPS: 0.4531\n",
      "Epoch [491/500], Loss: 1.6489856243133545, PSNR: 10.0145, SSIM: 0.1717, LPIPS: 0.4514\n",
      "Epoch [492/500], Loss: 1.6487758159637451, PSNR: 10.0201, SSIM: 0.1718, LPIPS: 0.4511\n",
      "Epoch [493/500], Loss: 1.6499652862548828, PSNR: 10.0206, SSIM: 0.1718, LPIPS: 0.4529\n",
      "Epoch [494/500], Loss: 1.6510341167449951, PSNR: 10.0361, SSIM: 0.1722, LPIPS: 0.4507\n",
      "Epoch [495/500], Loss: 1.6479835510253906, PSNR: 10.0291, SSIM: 0.1721, LPIPS: 0.4524\n",
      "Epoch [496/500], Loss: 1.6463019847869873, PSNR: 10.0381, SSIM: 0.1723, LPIPS: 0.4515\n",
      "Epoch [497/500], Loss: 1.6481989622116089, PSNR: 10.0508, SSIM: 0.1725, LPIPS: 0.4501\n",
      "Epoch [498/500], Loss: 1.6486315727233887, PSNR: 10.0449, SSIM: 0.1725, LPIPS: 0.4531\n",
      "Epoch [499/500], Loss: 1.6471308469772339, PSNR: 10.0582, SSIM: 0.1727, LPIPS: 0.4502\n",
      "Epoch [500/500], Loss: 1.6448805332183838, PSNR: 10.0576, SSIM: 0.1726, LPIPS: 0.4509\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from lpips import LPIPS\n",
    "\n",
    "# DAM\n",
    "class DualAttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(DualAttentionModule, self).__init__()\n",
    "        self.initial_conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.initial_relu = nn.LeakyReLU(0.1)\n",
    "        self.pa_conv1 = nn.Conv2d(in_channels, max(1, in_channels // 8), kernel_size=1)\n",
    "        self.pa_relu1 = nn.LeakyReLU(0.1)\n",
    "        self.pa_bn1 = nn.BatchNorm2d(max(1, in_channels // 8))\n",
    "        self.pa_conv2 = nn.Conv2d(max(1, in_channels // 8), 1, kernel_size=1)\n",
    "        self.pa_sigmoid = nn.Sigmoid()\n",
    "        self.ca_gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.ca_conv1 = nn.Conv2d(in_channels, max(1, in_channels // 8), kernel_size=1)\n",
    "        self.ca_relu1 = nn.LeakyReLU(0.1)\n",
    "        self.ca_conv2 = nn.Conv2d(max(1, in_channels // 8), in_channels, kernel_size=1)\n",
    "        self.ca_sigmoid = nn.Sigmoid()\n",
    "        self.fe_conv = nn.Conv2d(in_channels * 2, in_channels, kernel_size=3, padding=1)\n",
    "        self.fe_tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x2 = self.initial_conv(x)\n",
    "        x2 = self.initial_relu(x2)\n",
    "        pa = self.pa_conv1(x2)\n",
    "        pa = self.pa_relu1(pa)\n",
    "        pa = self.pa_bn1(pa)\n",
    "        pa = self.pa_conv2(pa)\n",
    "        pa = self.pa_sigmoid(pa)\n",
    "        pa_out = x2 * pa\n",
    "        ca = self.ca_gap(x2)\n",
    "        ca = self.ca_conv1(ca)\n",
    "        ca = self.ca_relu1(ca)\n",
    "        ca = self.ca_conv2(ca)\n",
    "        ca = self.ca_sigmoid(ca)\n",
    "        ca_out = x2 * ca\n",
    "        concat = torch.cat([pa_out, ca_out], dim=1)\n",
    "        fe = self.fe_conv(concat)\n",
    "        fe = self.fe_tanh(fe)\n",
    "        out = fe + x + x + x2\n",
    "        return out\n",
    "\n",
    "class FeatureEnhancementModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(FeatureEnhancementModule, self).__init__()\n",
    "\n",
    "        def conv_block(in_channels, out_channels, pool=True):\n",
    "            layers = [\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            ]\n",
    "            if pool:\n",
    "                layers.append(nn.MaxPool2d(2))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        def dilated_conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=2, dilation=2),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        self.fd_conv1 = conv_block(in_channels, in_channels, pool=False)\n",
    "        self.fd_conv2 = conv_block(in_channels, in_channels, pool=False)\n",
    "        self.fd_downsample1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, stride=2)\n",
    "        self.fd_conv3 = conv_block(in_channels, in_channels, pool=False)\n",
    "        self.fd_conv4 = conv_block(in_channels, in_channels, pool=False)\n",
    "        self.fd_downsample2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, stride=2)\n",
    "        self.fd_conv5 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.fd_relu5 = nn.LeakyReLU(0.1)\n",
    "        self.fd_bn5 = nn.BatchNorm2d(in_channels)\n",
    "        self.fd_dilated_conv1 = dilated_conv_block(in_channels, in_channels)\n",
    "        self.fd_dilated_conv2 = dilated_conv_block(in_channels, in_channels)\n",
    "        self.fd_upsample1 = nn.ConvTranspose2d(in_channels, in_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.fd_upsample2 = nn.ConvTranspose2d(in_channels, in_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.fd_tanh = nn.Tanh()\n",
    "\n",
    "        self.fc_conv1 = conv_block(in_channels, in_channels, pool=False)\n",
    "        self.fc_conv2 = conv_block(in_channels, in_channels, pool=False)\n",
    "        self.fc_downsample1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, stride=2)\n",
    "        self.fc_conv3 = conv_block(in_channels, in_channels, pool=False)\n",
    "        self.fc_conv4 = conv_block(in_channels, in_channels, pool=False)\n",
    "        self.fc_downsample2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, stride=2)\n",
    "        self.fc_conv5 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.fc_relu5 = nn.LeakyReLU(0.1)\n",
    "        self.fc_bn5 = nn.BatchNorm2d(in_channels)\n",
    "        self.fc_dilated_conv1 = dilated_conv_block(in_channels, in_channels)\n",
    "        self.fc_dilated_conv2 = dilated_conv_block(in_channels, in_channels)\n",
    "        self.fc_upsample1 = nn.ConvTranspose2d(in_channels, in_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.fc_upsample2 = nn.ConvTranspose2d(in_channels, in_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.fc_tanh = nn.Tanh()\n",
    "        self.fc_sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        fd = self.fd_conv1(x)\n",
    "        fd = self.fd_conv2(fd)\n",
    "        fd = self.fd_downsample1(fd)\n",
    "        fd = self.fd_conv3(fd)\n",
    "        fd = self.fd_conv4(fd)\n",
    "        fd = self.fd_downsample2(fd)\n",
    "        fd = self.fd_conv5(fd)\n",
    "        fd = self.fd_relu5(fd)\n",
    "        fd = self.fd_bn5(fd)\n",
    "        fd = self.fd_dilated_conv1(fd)\n",
    "        fd = self.fd_dilated_conv2(fd)\n",
    "        fd = self.fd_upsample1(fd)\n",
    "        fd = self.fd_upsample2(fd)\n",
    "        fd = self.fd_tanh(fd)\n",
    "        fd_out = fd + x\n",
    "\n",
    "        fc = self.fc_conv1(x)\n",
    "        fc = self.fc_conv2(fc)\n",
    "        fc = self.fc_downsample1(fc)\n",
    "        fc = self.fc_conv3(fc)\n",
    "        fc = self.fc_conv4(fc)\n",
    "        fc = self.fc_downsample2(fc)\n",
    "        fc = self.fc_conv5(fc)\n",
    "        fc = self.fc_relu5(fc)\n",
    "        fc = self.fc_bn5(fc)\n",
    "        fc = self.fc_dilated_conv1(fc)\n",
    "        fc = self.fc_dilated_conv2(fc)\n",
    "        fc = self.fc_upsample1(fc)\n",
    "        fc = self.fc_upsample2(fc)\n",
    "        fc = self.fc_tanh(fc)\n",
    "        fc = self.fc_sigmoid(fc)\n",
    "        fc_out = fc / x\n",
    "\n",
    "        out = fd_out + fc_out\n",
    "        return out\n",
    "\n",
    "# 定义 HDRNet 模型\n",
    "class HDRNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(HDRNet, self).__init__()\n",
    "        self.dam = DualAttentionModule(in_channels)\n",
    "        self.fem = FeatureEnhancementModule(in_channels)\n",
    "        self.final_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1_dam = self.dam(x1)\n",
    "        x2_dam = self.dam(x2)\n",
    "        x3 = x1 * x1_dam\n",
    "        x4 = x2 * x2_dam\n",
    "        x_fusion = x3 + x4\n",
    "        x_enhanced = self.fem(x_fusion)\n",
    "        out = self.final_conv(x_enhanced)\n",
    "        return out\n",
    "\n",
    "# HDRLoss\n",
    "class HDRLoss(nn.Module):\n",
    "    def __init__(self, vgg_model, discriminator, real_label, fake_label, criterion):\n",
    "        super(HDRLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.vgg = vgg_model\n",
    "        self.discriminator = discriminator\n",
    "        self.real_label = real_label\n",
    "        self.fake_label = fake_label\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, Ihdr, Iref, Iu, Io):\n",
    "        mse_loss = self.mse_loss(Ihdr, Iref)\n",
    "        Ihdr_vgg = self.vgg(Ihdr)\n",
    "        Iref_vgg = self.vgg(Iref)\n",
    "        perceptual_loss = F.mse_loss(Ihdr_vgg, Iref_vgg)\n",
    "        mef_ssim_loss = calculate_mef_ssim(Ihdr, Iref)\n",
    "        d_loss, g_loss = calculate_adversarial_loss(Ihdr, Iref, self.discriminator, self.real_label, self.fake_label, self.criterion)\n",
    "        global_local_contrast_loss = calculate_global_local_contrast_loss(Ihdr, Iref, Iu, Io, self.vgg)\n",
    "        total_loss = mse_loss + 0.1 * mef_ssim_loss + 0.1 * g_loss + 0.1 * perceptual_loss + 0.1 * global_local_contrast_loss\n",
    "        return total_loss\n",
    "\n",
    "def calculate_mef_ssim(Ihdr, Iref):\n",
    "    Ihdr_np = Ihdr.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
    "    Iref_np = Iref.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
    "    ssim_value = ssim(Ihdr_np, Iref_np, win_size=7, channel_axis=2, data_range=1.0)\n",
    "    return 1 - ssim_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1)\n",
    "\n",
    "def calculate_adversarial_loss(Ihdr, Iref, discriminator, real_label, fake_label, criterion):\n",
    "    real_output = discriminator(Iref)\n",
    "    fake_output = discriminator(Ihdr)\n",
    "    \n",
    "    # 创建与输出大小匹配的标签\n",
    "    real_label_resized = real_label.expand_as(real_output)\n",
    "    fake_label_resized = fake_label.expand_as(fake_output)\n",
    "    \n",
    "    real_loss = criterion(real_output, real_label_resized)\n",
    "    fake_loss = criterion(fake_output, fake_label_resized)\n",
    "    d_loss = (real_loss + fake_loss) / 2\n",
    "    g_loss = criterion(fake_output, real_label_resized)\n",
    "    return d_loss, g_loss\n",
    "\n",
    "\n",
    "def calculate_global_local_contrast_loss(Ihdr, Iref, Iu, Io, vgg_model):\n",
    "    def extract_features(image):\n",
    "        features = vgg_model(image)\n",
    "        return features\n",
    "    Ihdr_features = extract_features(Ihdr)\n",
    "    Iref_features = extract_features(Iref)\n",
    "    Iu_features = extract_features(Iu)\n",
    "    Io_features = extract_features(Io)\n",
    "    global_loss = F.mse_loss(Ihdr_features, Iref_features) + F.mse_loss(Ihdr_features, Iu_features) + F.mse_loss(Ihdr_features, Io_features)\n",
    "    def calculate_local_loss(Ihdr, Iref, Iu, Io, vgg_model):\n",
    "        P = 4\n",
    "        Ihdr_patches = Ihdr.unfold(2, P, P).unfold(3, P, P)\n",
    "        Iref_patches = Iref.unfold(2, P, P).unfold(3, P, P)\n",
    "        Iu_patches = Iu.unfold(2, P, P).unfold(3, P, P)\n",
    "        Io_patches = Io.unfold(2, P, P).unfold(3, P, P)\n",
    "        local_loss = 0\n",
    "        for i in range(P):\n",
    "            for j in range(P):\n",
    "                Ihdr_patch = Ihdr_patches[:, :, i, j, :, :]\n",
    "                Iref_patch = Iref_patches[:, :, i, j, :, :]\n",
    "                Iu_patch = Iu_patches[:, :, i, j, :, :]\n",
    "                Io_patch = Io_patches[:, :, i, j, :, :]\n",
    "                Ihdr_features = extract_features(Ihdr_patch)\n",
    "                Iref_features = extract_features(Iref_patch)\n",
    "                Iu_features = extract_features(Iu_patch)\n",
    "                Io_features = extract_features(Io_patch)\n",
    "                local_loss += F.mse_loss(Ihdr_features, Iref_features) + F.mse_loss(Ihdr_features, Iu_features) + F.mse_loss(Ihdr_features, Io_features)\n",
    "        return local_loss / (P * P)\n",
    "    local_loss = calculate_local_loss(Ihdr, Iref, Iu, Io, vgg_model)\n",
    "    return global_loss + local_loss\n",
    "\n",
    "def load_image(image_path, transform):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = F.mse_loss(img1, img2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
    "\n",
    "def train_model(model, loss_fn, optimizer, dataloader, num_epochs, device):\n",
    "    lpips_fn = LPIPS(net='alex').to(device)\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        avg_psnr = 0\n",
    "        avg_ssim = 0\n",
    "        avg_lpips = 0\n",
    "        for batch in dataloader:\n",
    "            input_image1, input_image2, ref_image = [item.to(device) for item in batch]\n",
    "            output_image = model(input_image1, input_image2)\n",
    "            loss = loss_fn(output_image, ref_image, input_image1, input_image2)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 计算评价指标\n",
    "            psnr_value = calculate_psnr(output_image, ref_image).item()\n",
    "            ssim_value = ssim(output_image.squeeze(0).permute(1, 2, 0).detach().cpu().numpy(), \n",
    "                              ref_image.squeeze(0).permute(1, 2, 0).detach().cpu().numpy(), \n",
    "                              win_size=7, channel_axis=2, data_range=1.0)\n",
    "            lpips_value = lpips_fn(output_image, ref_image).item()\n",
    "            avg_psnr += psnr_value\n",
    "            avg_ssim += ssim_value\n",
    "            avg_lpips += lpips_value\n",
    "\n",
    "        avg_psnr /= len(dataloader)\n",
    "        avg_ssim /= len(dataloader)\n",
    "        avg_lpips /= len(dataloader)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}, PSNR: {avg_psnr:.4f}, SSIM: {avg_ssim:.4f}, LPIPS: {avg_lpips:.4f}')\n",
    "\n",
    "# 创建模型和损失函数实例\n",
    "vgg_model = vgg16(pretrained=True).features[:16].eval().to('cuda')\n",
    "for param in vgg_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "discriminator = Discriminator(in_channels=3).to('cuda')\n",
    "criterion = nn.BCELoss()\n",
    "real_label = torch.ones(1, dtype=torch.float32).to('cuda')\n",
    "fake_label = torch.zeros(1, dtype=torch.float32).to('cuda')\n",
    "\n",
    "\n",
    "model = HDRNet(in_channels=3, out_channels=3).to('cuda')\n",
    "loss_fn = HDRLoss(vgg_model=vgg_model, discriminator=discriminator, real_label=real_label, fake_label=fake_label, criterion=criterion)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "image_path1 = '1.JPG'\n",
    "image_path2 = '9.JPG'\n",
    "ref_image_path = '221.PNG'\n",
    "\n",
    "input_image1 = load_image(image_path1, transform).to('cuda')\n",
    "input_image2 = load_image(image_path2, transform).to('cuda')\n",
    "ref_image = load_image(ref_image_path, transform).to('cuda')\n",
    "\n",
    "dataloader = [(input_image1, input_image2, ref_image)]\n",
    "\n",
    "train_model(model, loss_fn, optimizer, dataloader, num_epochs=500, device='cuda')\n",
    "\n",
    "torch.save(model.state_dict(), 'hdrnet_model.pth')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
