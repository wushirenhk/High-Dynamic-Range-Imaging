{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a7a4f87",
   "metadata": {},
   "source": [
    "论文中DAM图示如下：  \n",
    "![](20240523103415.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa90a2fe",
   "metadata": {},
   "source": [
    "上图网络结构如下：\n",
    "\n",
    "1. **原始图像（记作1）**\n",
    "2. **输入图像处理**：\n",
    "    - **卷积层（绿色）**\n",
    "    - **带泄漏的ReLU激活函数（黄色）**\n",
    "    - 处理完成，记作2\n",
    "3. **像素注意力（PA）模块**:\n",
    "    - **卷积层（绿色）**\n",
    "    - **带泄漏的ReLU激活函数（黄色）**\n",
    "    - **批归一化层（蓝色）**\n",
    "    - **卷积层（绿色）**\n",
    "    - **Sigmoid函数（橙色）**\n",
    "    - 处理完成，记作3.1\n",
    "    - 3.1与2相乘，PA正式结束，记作3.2\n",
    "4. **通道注意力（CA）模块**:\n",
    "    - **全局平均池化（GAP，灰色）**\n",
    "    - **卷积层（绿色）**\n",
    "    - **带泄漏的ReLU激活函数（黄色）**\n",
    "    - **卷积层（绿色）**\n",
    "    - **Sigmoid函数（橙色）**\n",
    "    - 处理完成，记作3.3\n",
    "    - 3.3与2相乘，记作3.4\n",
    "    - CA处理完成\n",
    "5. **融合操作**:\n",
    "    - 3.2与3.4连接，记作4\n",
    "6. **处理融合结果**:\n",
    "    - **卷积层（绿色）**\n",
    "    - **Tanh激活函数（浅粉色）**\n",
    "    - 处理完成，记作5\n",
    "7. **输出结果**:\n",
    "    - 5和两个1以及2相加，处理完成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DualAttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(DualAttentionModule, self).__init__()\n",
    "\n",
    "        # 输入图像的初始处理\n",
    "        self.initial_conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.initial_relu = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        # 像素注意力模块\n",
    "        self.pa_conv1 = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.pa_relu1 = nn.LeakyReLU(0.1)\n",
    "        self.pa_bn1 = nn.BatchNorm2d(in_channels // 8)\n",
    "        self.pa_conv2 = nn.Conv2d(in_channels // 8, 1, kernel_size=1)\n",
    "        self.pa_sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # 通道注意力模块\n",
    "        self.ca_gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.ca_conv1 = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.ca_relu1 = nn.LeakyReLU(0.1)\n",
    "        self.ca_conv2 = nn.Conv2d(in_channels // 8, in_channels, kernel_size=1)\n",
    "        self.ca_sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # 特征增强模块\n",
    "        self.fe_conv = nn.Conv2d(in_channels * 2, in_channels, kernel_size=3, padding=1)\n",
    "        self.fe_tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始处理\n",
    "        x2 = self.initial_conv(x)\n",
    "        x2 = self.initial_relu(x2)\n",
    "        \n",
    "        # 像素注意力CA\n",
    "        pa = self.pa_conv1(x2)\n",
    "        pa = self.pa_relu1(pa)\n",
    "        pa = self.pa_bn1(pa)\n",
    "        pa = self.pa_conv2(pa)\n",
    "        pa = self.pa_sigmoid(pa)\n",
    "        pa_out = x2 * pa\n",
    "        \n",
    "        # 通道注意力PA\n",
    "        ca = self.ca_gap(x2)\n",
    "        ca = self.ca_conv1(ca)\n",
    "        ca = self.ca_relu1(ca)\n",
    "        ca = self.ca_conv2(ca)\n",
    "        ca = self.ca_sigmoid(ca)\n",
    "        ca_out = x2 * ca\n",
    "        \n",
    "        # 拼接PA和CA的输出\n",
    "        concat = torch.cat([pa_out, ca_out], dim=1)\n",
    "        \n",
    "        # 最后两层\n",
    "        fe = self.fe_conv(concat)\n",
    "        fe = self.fe_tanh(fe)\n",
    "        \n",
    "        # 输出\n",
    "        out = fe + x + x + x2\n",
    "        \n",
    "        return out\n",
    "\n",
    "class HDRNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(HDRNet, self).__init__()\n",
    "        self.dam1 = DualAttentionModule(in_channels)\n",
    "        self.dam2 = DualAttentionModule(in_channels)\n",
    "        self.final_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dam1(x)\n",
    "        x = self.dam2(x)\n",
    "        x = self.final_conv(x)\n",
    "        return x\n",
    "\n",
    "# 测试\n",
    "model = HDRNet(in_channels=64, out_channels=64)\n",
    "input_image = torch.randn(1, 64, 256, 256)  # 输入张量\n",
    "output_image = model(input_image)\n",
    "print(output_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c6ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
