{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a7a4f87",
   "metadata": {},
   "source": [
    "更新的DAM实现了更大的板块：  \n",
    "![](过曝光+欠曝光同时处理.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa90a2fe",
   "metadata": {},
   "source": [
    "上图网络结构如下：\n",
    "\n",
    "过曝光和欠曝光图像分别进入我们已有的DAM模型  \n",
    "处理后分别于原图相乘再相加，得到可以直接进入下一阶段，即特征增强的图像  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DualAttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(DualAttentionModule, self).__init__()\n",
    "\n",
    "        # 输入图像的初始处理\n",
    "        self.initial_conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.initial_relu = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        # 像素注意力模块\n",
    "        self.pa_conv1 = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.pa_relu1 = nn.LeakyReLU(0.1)\n",
    "        self.pa_bn1 = nn.BatchNorm2d(in_channels // 8)\n",
    "        self.pa_conv2 = nn.Conv2d(in_channels // 8, 1, kernel_size=1)\n",
    "        self.pa_sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # 通道注意力模块\n",
    "        self.ca_gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.ca_conv1 = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.ca_relu1 = nn.LeakyReLU(0.1)\n",
    "        self.ca_conv2 = nn.Conv2d(in_channels // 8, in_channels, kernel_size=1)\n",
    "        self.ca_sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # 特征增强模块\n",
    "        self.fe_conv = nn.Conv2d(in_channels * 2, in_channels, kernel_size=3, padding=1)\n",
    "        self.fe_tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始处理\n",
    "        x2 = self.initial_conv(x)\n",
    "        x2 = self.initial_relu(x2)\n",
    "        \n",
    "        # 像素注意力\n",
    "        pa = self.pa_conv1(x2)\n",
    "        pa = self.pa_relu1(pa)\n",
    "        pa = self.pa_bn1(pa)\n",
    "        pa = self.pa_conv2(pa)\n",
    "        pa = self.pa_sigmoid(pa)\n",
    "        pa_out = x2 * pa\n",
    "        \n",
    "        # 通道注意力\n",
    "        ca = self.ca_gap(x2)\n",
    "        ca = self.ca_conv1(ca)\n",
    "        ca = self.ca_relu1(ca)\n",
    "        ca = self.ca_conv2(ca)\n",
    "        ca = self.ca_sigmoid(ca)\n",
    "        ca_out = x2 * ca\n",
    "        \n",
    "        # 拼接PA和CA的输出\n",
    "        concat = torch.cat([pa_out, ca_out], dim=1)\n",
    "        \n",
    "        # 最后两层\n",
    "        fe = self.fe_conv(concat)\n",
    "        fe = self.fe_tanh(fe)\n",
    "        \n",
    "        # 输出\n",
    "        out = fe + x + x + x2\n",
    "        \n",
    "        return out\n",
    "\n",
    "class HDRNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(HDRNet, self).__init__()\n",
    "        self.dam = DualAttentionModule(in_channels)\n",
    "        self.final_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # 欠曝光（记作1，处理后记作3）\n",
    "        x1_dam = self.dam(x1)\n",
    "        # 过曝光（记作2，处理后记作4）\n",
    "        x2_dam = self.dam(x2)\n",
    "\n",
    "        # 1和3相乘记作5\n",
    "        x3 = x1 * x1_dam\n",
    "\n",
    "        # 2和4相乘记作6\n",
    "        x4 = x2 * x2_dam\n",
    "\n",
    "        # 5和6相加\n",
    "        out = x3 + x4\n",
    "\n",
    "        # 最终卷积\n",
    "        out = self.final_conv(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# 测试\n",
    "def test_model_with_images(image_path1, image_path2, model):\n",
    "    # 预处理\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    # 加载图像\n",
    "    image1 = Image.open(image_path1).convert('RGB')\n",
    "    image2 = Image.open(image_path2).convert('RGB')\n",
    "    input_image1 = transform(image1).unsqueeze(0)  # 添加批次维度\n",
    "    input_image2 = transform(image2).unsqueeze(0)  # 添加批次维度\n",
    "\n",
    "    # 将图像输入模型\n",
    "    model.eval()  # 设置为评估模式\n",
    "    with torch.no_grad():\n",
    "        output_image = model(input_image1, input_image2)\n",
    "\n",
    "    # 反归一化并转换为PIL图像\n",
    "    output_image = output_image.squeeze(0).detach().cpu()\n",
    "    output_image = (output_image * 0.5 + 0.5).clamp(0, 1)  # 反归一化\n",
    "    output_image = transforms.ToPILImage()(output_image)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    axs[0].imshow(image1)\n",
    "    axs[0].set_title('Underexposed Image')\n",
    "    axs[0].axis('off')\n",
    "    axs[1].imshow(image2)\n",
    "    axs[1].set_title('Overexposed Image')\n",
    "    axs[1].axis('off')\n",
    "    axs[2].imshow(output_image)\n",
    "    axs[2].set_title('Output Image')\n",
    "    axs[2].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "model = HDRNet(in_channels=3, out_channels=3)\n",
    "\n",
    "# 测试图片路径\n",
    "image_path1 = '欠.jpg'  # 欠曝光\n",
    "image_path2 = '过.jpg'  # 过曝光\n",
    "\n",
    "# 测试\n",
    "test_model_with_images(image_path1, image_path2, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
